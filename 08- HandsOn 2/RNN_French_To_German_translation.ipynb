{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_French_To_German_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPM6QkbCLkVfIqlArZaq8Yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank-Holla/TSAI-END-Program/blob/main/08-%20HandsOn%202/RNN_French_To_German_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtEuTxN7QToi"
      },
      "source": [
        "# RNN based machine translation - French to German\r\n",
        "\r\n",
        "RNN based model to predict German translations from French sentences.\r\n",
        "\r\n",
        "Based on encoder-decoder architecture. Encoder learns from French sentence training data to generate context vector. Inputs to the encoder are hidden state from previous cell and current timestep's embedded input.\r\n",
        "\r\n",
        "Decoder takes in the hidden state of previous decoder timestep and also the predicted word from the previous timestep or ground truth (teacher forcing). Hidden state of the decoder are fed to a linear layer to predict the actual word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2zmWKkwQOWj"
      },
      "source": [
        "# Import necessary packages\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "# Extension of Flickr30K dataset. \r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import time\r\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGz8ROQp6UGp"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELWgBKPwDmbh"
      },
      "source": [
        "### Download and load spacy models for DE and EN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwL9Q64E6n_f",
        "outputId": "b373ec2b-69f1-45a9-9cd8-f4f4e141e6e6"
      },
      "source": [
        "# Download and load spacy models for DE and FR languages. To be used for tokenization.\r\n",
        "%%bash\r\n",
        "python -m spacy download fr\r\n",
        "python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py): started\n",
            "  Building wheel for fr-core-news-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=21c5ea5515cb01193187128c860c6409b52712d82a19933a0c8753a9fa7760a7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d1bpu5xb/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py): started\n",
            "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=52b87f33611f3c2a19b8769a29c06bafad4b907ba3a15582108b97e96699477f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fi1jnuzm/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlqy_r7d7P_X"
      },
      "source": [
        "# After linking spacy.load('de_core_news_sm') -> spacy.load('de')\r\n",
        "spacy_de = spacy.load('de')\r\n",
        "# After linking spacy.load('fr_core_news_sm') -> spacy.load('fr')\r\n",
        "spacy_fr = spacy.load('fr')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOE25mevCYcd"
      },
      "source": [
        "### Prepare tokenizers\r\n",
        "\r\n",
        "Takes in string and returns list of tokens. Will be passed to torchtext.\r\n",
        "\r\n",
        "In the paper we are implementing, they find it beneficial to reverse the order of the input which they believe \"introduces many short term dependencies in the data that make the optimization problem much easier\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEdu5UATCVky"
      },
      "source": [
        "# Tokenizer for French. Returns reversed tokens.\r\n",
        "def tokenize_fr(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes French text from a string into a list of strings (tokens) and reverses it\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)][::-1]\r\n",
        "\r\n",
        "def tokenize_de(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes German text from a string into a list of strings (tokens)\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLZErbgADAvQ",
        "outputId": "567597b0-f722-4856-a524-c1971cc4067e"
      },
      "source": [
        "tokenize_fr(\"bonjour ma chérie!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!', 'chérie', 'ma', 'bonjour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ELLrJPA5ef"
      },
      "source": [
        "### Prepare FIELDS\r\n",
        "\r\n",
        "Defines a datatype together with instructions for converting to Tensor. holds a Vocab object that defines the set of possible values\r\n",
        "    for elements of the field and their corresponding numerical representations.\r\n",
        "\r\n",
        "SRC is German and TRG is EN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Hnvmg7Bwq-"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_fr, init_token = '<SOS>', eos_token = '<EOS>', lower = True)\r\n",
        "TRG = Field(tokenize = tokenize_de, init_token = '<SOS>', eos_token = '<EOS>', lower = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyYaF216DGFG",
        "outputId": "d4f077d0-58e4-4bff-8d00-e3cbf5fed4ad"
      },
      "source": [
        "SRC.__dict__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_first': False,\n",
              " 'dtype': torch.int64,\n",
              " 'eos_token': '<EOS>',\n",
              " 'fix_length': None,\n",
              " 'include_lengths': False,\n",
              " 'init_token': '<SOS>',\n",
              " 'is_target': False,\n",
              " 'lower': True,\n",
              " 'pad_first': False,\n",
              " 'pad_token': '<pad>',\n",
              " 'postprocessing': None,\n",
              " 'preprocessing': None,\n",
              " 'sequential': True,\n",
              " 'stop_words': None,\n",
              " 'tokenize': <function __main__.tokenize_fr>,\n",
              " 'truncate_first': False,\n",
              " 'unk_token': '<unk>',\n",
              " 'use_vocab': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXdGg6FRDfLJ"
      },
      "source": [
        "### Download Multi30K dataset and load train, test and val data.\r\n",
        "\r\n",
        "Data stored under .data/multi30k/\r\n",
        "\r\n",
        "Train and Validation data for french is not available in default pytorch download. Hence downloading the raw data and placing them in .data folder.\r\n",
        "\r\n",
        "\"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.fr.gz\"\r\n",
        "\r\n",
        "\"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.fr.gz\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6lFWxCGmt2D",
        "outputId": "6c97f997-eaac-4838-c0c5-88c4e8517416"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.fr.gz\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 17:35:43--  https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.fr.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 604242 (590K) [application/octet-stream]\n",
            "Saving to: ‘train.fr.gz’\n",
            "\n",
            "\rtrain.fr.gz           0%[                    ]       0  --.-KB/s               \rtrain.fr.gz         100%[===================>] 590.08K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-12-17 17:35:43 (12.2 MB/s) - ‘train.fr.gz’ saved [604242/604242]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm5rylNCnE9y",
        "outputId": "675ea107-91ed-4390-ee5f-866a53c63f9c"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.fr.gz\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-17 17:35:45--  https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.fr.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23001 (22K) [application/octet-stream]\n",
            "Saving to: ‘val.fr.gz’\n",
            "\n",
            "\rval.fr.gz             0%[                    ]       0  --.-KB/s               \rval.fr.gz           100%[===================>]  22.46K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-12-17 17:35:45 (13.1 MB/s) - ‘val.fr.gz’ saved [23001/23001]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgnxlqRYm0gG"
      },
      "source": [
        "mv train.fr.gz .data/multi30k/"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJi7-z2JnIoq"
      },
      "source": [
        "mv val.fr.gz .data/multi30k/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJuJwCCfnX-w"
      },
      "source": [
        "!gzip -dk .data/multi30k/train.fr.gz"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-2lcQHMn4r9"
      },
      "source": [
        "!gzip -dk .data/multi30k/val.fr.gz"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hAukodUsGP5",
        "outputId": "2b04f697-8ea4-4660-ea0d-685138540b56"
      },
      "source": [
        "ls .data/multi30k/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz  train.de     training.tar.gz  val.fr.gz\n",
            "test2016.de                train.en     val.de           validation.tar.gz\n",
            "test2016.en                train.fr     val.en\n",
            "test2016.fr                train.fr.gz  val.fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Owjo4F6EiE3"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.fr', '.de'), fields = (SRC, TRG))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d5sdS65E6GL",
        "outputId": "23be8402-e63d-4793-e8b4-44e5db6f7f05"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\r\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\r\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t770SUkAE-IS",
        "outputId": "0ab69cf0-0f45-4e48-fcc1-e17c6a629fb0"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'src': ['.', 'buissons', 'de', 'près', 'dehors', 'sont', 'blancs', 'hommes', 'jeunes', 'deux'], 'trg': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qk5FVRshYth-",
        "outputId": "74671b64-6c0a-49f3-e366-ef4e54a0ad9c"
      },
      "source": [
        "sent = ' '.join([word for word in train_data.examples[0].__dict__['src'][::-1]])\r\n",
        "sent"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'deux jeunes hommes blancs sont dehors près de buissons .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHptOa2BbWgP"
      },
      "source": [
        "### Build vocabulary for SRC and TRG\r\n",
        "\r\n",
        "Vocabulary will associate each unique tokens with an index. Only tokens that appear atleast 2 times are considered. Other such words are replaced by <UNK>. Vocab object built on only training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMUtz69b6SQ"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycM8c8q8cU6v",
        "outputId": "6b742204-95da-41f7-d734-0e6c30870e38"
      },
      "source": [
        "vars(SRC)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_first': False,\n",
              " 'dtype': torch.int64,\n",
              " 'eos_token': '<EOS>',\n",
              " 'fix_length': None,\n",
              " 'include_lengths': False,\n",
              " 'init_token': '<SOS>',\n",
              " 'is_target': False,\n",
              " 'lower': True,\n",
              " 'pad_first': False,\n",
              " 'pad_token': '<pad>',\n",
              " 'postprocessing': None,\n",
              " 'preprocessing': None,\n",
              " 'sequential': True,\n",
              " 'stop_words': None,\n",
              " 'tokenize': <function __main__.tokenize_fr>,\n",
              " 'truncate_first': False,\n",
              " 'unk_token': '<unk>',\n",
              " 'use_vocab': True,\n",
              " 'vocab': <torchtext.vocab.Vocab at 0x7f51dae28a58>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muIzn2U_cmnv",
        "outputId": "05148193-fb7f-43a4-ae66-d0e20f0c37c8"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\r\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 6462\n",
            "Unique tokens in target (en) vocabulary: 7855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6YYUzrCcwqG",
        "outputId": "c92b3a4b-23bc-4856-8ed4-6b62d851acce"
      },
      "source": [
        "# SRC.vocab dict has the following keys - freqs(provides word and its frequencies), itos(mapping of integer to string), \r\n",
        "# stoi(mapping of string to its integer) and vectors()\r\n",
        "print(SRC.vocab.__dict__.keys())\r\n",
        "SRC.vocab.__dict__"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['freqs', 'itos', 'stoi', 'vectors'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'.': 27686,\n",
              "          'buissons': 23,\n",
              "          'de': 14013,\n",
              "          'près': 800,\n",
              "          'dehors': 600,\n",
              "          'sont': 1941,\n",
              "          'blancs': 207,\n",
              "          'hommes': 1782,\n",
              "          'jeunes': 656,\n",
              "          'deux': 4068,\n",
              "          'géant': 18,\n",
              "          'poulies': 2,\n",
              "          'système': 3,\n",
              "          'un': 34942,\n",
              "          'fonctionner': 7,\n",
              "          'font': 364,\n",
              "          'casque': 278,\n",
              "          'en': 9878,\n",
              "          'plusieurs': 448,\n",
              "          'bois': 344,\n",
              "          'maisonnette': 2,\n",
              "          'une': 20624,\n",
              "          'dans': 8059,\n",
              "          'grimpe': 35,\n",
              "          'fille': 1756,\n",
              "          'petite': 618,\n",
              "          'fenêtre': 133,\n",
              "          'nettoyer': 22,\n",
              "          'pour': 1298,\n",
              "          'échelle': 56,\n",
              "          'sur': 7957,\n",
              "          'tient': 904,\n",
              "          'se': 1983,\n",
              "          'bleue': 501,\n",
              "          'chemise': 662,\n",
              "          'homme': 7888,\n",
              "          'manger': 114,\n",
              "          'à': 5326,\n",
              "          'préparent': 57,\n",
              "          'fourneaux': 5,\n",
              "          'aux': 411,\n",
              "          'sa': 948,\n",
              "          'observe': 28,\n",
              "          'autre': 874,\n",
              "          \"qu'\": 1376,\n",
              "          'tandis': 1796,\n",
              "          'guitare': 359,\n",
              "          'vert': 510,\n",
              "          'peluche': 47,\n",
              "          'ours': 17,\n",
              "          'sourit': 189,\n",
              "          'rue': 1458,\n",
              "          'la': 5651,\n",
              "          'lentement': 3,\n",
              "          'glissant': 32,\n",
              "          'tout': 532,\n",
              "          'portable': 186,\n",
              "          'son': 1481,\n",
              "          'parle': 218,\n",
              "          'branchée': 1,\n",
              "          'porte': 483,\n",
              "          'par': 903,\n",
              "          'passe': 210,\n",
              "          'sac': 345,\n",
              "          'gros': 262,\n",
              "          'avec': 7177,\n",
              "          'femme': 4454,\n",
              "          'nuit': 150,\n",
              "          'milieu': 234,\n",
              "          'au': 1796,\n",
              "          'barres': 17,\n",
              "          'des': 7406,\n",
              "          'dansent': 90,\n",
              "          'garçons': 355,\n",
              "          'cadence': 1,\n",
              "          'sautent': 79,\n",
              "          ',': 4800,\n",
              "          'filles': 429,\n",
              "          'cinq': 177,\n",
              "          'composée': 7,\n",
              "          'ballet': 10,\n",
              "          'classe': 75,\n",
              "          'escalier': 103,\n",
              "          \"d'\": 8139,\n",
              "          'haut': 293,\n",
              "          'du': 1689,\n",
              "          'chapeaux': 75,\n",
              "          'portent': 80,\n",
              "          'trois': 1096,\n",
              "          'dont': 94,\n",
              "          'gars': 313,\n",
              "          'quatre': 408,\n",
              "          'battent': 65,\n",
              "          'tâches': 6,\n",
              "          'chien': 1647,\n",
              "          'et': 7426,\n",
              "          'noir': 1359,\n",
              "          'tracteur': 26,\n",
              "          'conduit': 44,\n",
              "          'fluo': 22,\n",
              "          'orange': 417,\n",
              "          'uniforme': 85,\n",
              "          'ville': 397,\n",
              "          'attendent': 89,\n",
              "          'femmes': 1039,\n",
              "          'cake': 2,\n",
              "          'bundt': 1,\n",
              "          'sucre': 1,\n",
              "          'saupoudrer': 1,\n",
              "          'train': 1091,\n",
              "          'est': 3259,\n",
              "          'lunettes': 579,\n",
              "          'portant': 1341,\n",
              "          'peint': 101,\n",
              "          'arc-en-ciel': 14,\n",
              "          'grand': 427,\n",
              "          'devant': 1793,\n",
              "          'assise': 551,\n",
              "          'blanc': 1317,\n",
              "          'attaché': 25,\n",
              "          'également': 14,\n",
              "          'auquel': 3,\n",
              "          'banc': 310,\n",
              "          'couché': 30,\n",
              "          'instruments': 83,\n",
              "          'leurs': 371,\n",
              "          'cercle': 33,\n",
              "          'assis': 1667,\n",
              "          'personnes': 1951,\n",
              "          'partition': 9,\n",
              "          'leur': 227,\n",
              "          'lisant': 82,\n",
              "          'clarinette': 5,\n",
              "          'ensemble': 332,\n",
              "          'jouent': 619,\n",
              "          'âgées': 65,\n",
              "          'groupe': 1682,\n",
              "          'chaussée': 24,\n",
              "          'couchée': 10,\n",
              "          'cassée': 6,\n",
              "          \"s'\": 787,\n",
              "          'structure': 77,\n",
              "          'grande': 249,\n",
              "          'métro': 114,\n",
              "          'bouche': 90,\n",
              "          'entrée': 34,\n",
              "          \"l'\": 4284,\n",
              "          'gens': 1126,\n",
              "          'foule': 528,\n",
              "          'importante': 3,\n",
              "          'dos': 276,\n",
              "          'tatouer': 2,\n",
              "          'faisant': 540,\n",
              "          'sable': 240,\n",
              "          'le': 3699,\n",
              "          'bascule': 10,\n",
              "          'manège': 41,\n",
              "          'petit': 864,\n",
              "          'enfants': 978,\n",
              "          'route': 266,\n",
              "          'drapeau': 81,\n",
              "          'réfléchissant': 9,\n",
              "          'gilet': 121,\n",
              "          'vêtu': 744,\n",
              "          'scène': 330,\n",
              "          'représentant': 38,\n",
              "          'peinture': 61,\n",
              "          'étudie': 11,\n",
              "          'encombré': 5,\n",
              "          'trottoir': 549,\n",
              "          'bleu': 1055,\n",
              "          'manteau': 218,\n",
              "          'vêtue': 309,\n",
              "          'personne': 769,\n",
              "          'descend': 85,\n",
              "          'pantalon': 290,\n",
              "          'habillé': 144,\n",
              "          'jeux': 73,\n",
              "          'aire': 33,\n",
              "          'rouge': 1454,\n",
              "          'corde': 122,\n",
              "          'enfant': 985,\n",
              "          'bieber': 1,\n",
              "          'justin': 1,\n",
              "          'ressemble': 23,\n",
              "          'je': 16,\n",
              "          'que': 865,\n",
              "          'sais': 2,\n",
              "          'tu': 3,\n",
              "          'souriant': 194,\n",
              "          'chose': 437,\n",
              "          'quelque': 449,\n",
              "          'regarde': 874,\n",
              "          'jaune': 664,\n",
              "          'noire': 385,\n",
              "          'veste': 563,\n",
              "          'jeune': 1819,\n",
              "          'café': 96,\n",
              "          'tasse': 46,\n",
              "          'urinoir': 2,\n",
              "          'debout': 1994,\n",
              "          'arrière-plan': 426,\n",
              "          'multicolore': 37,\n",
              "          'fond': 41,\n",
              "          'marchant': 513,\n",
              "          'bière': 75,\n",
              "          'seul': 39,\n",
              "          'vieil': 202,\n",
              "          'police': 36,\n",
              "          'fourgon': 3,\n",
              "          'maître': 5,\n",
              "          'dressé': 2,\n",
              "          'policier': 60,\n",
              "          'enneigée': 99,\n",
              "          'vélo': 645,\n",
              "          'ouvert': 21,\n",
              "          'arrière': 170,\n",
              "          'discutent': 53,\n",
              "          'cravate': 47,\n",
              "          'blanche': 580,\n",
              "          'vêtus': 155,\n",
              "          'tous': 96,\n",
              "          'machines': 15,\n",
              "          'travaille': 168,\n",
              "          'mis': 7,\n",
              "          'chapeau': 403,\n",
              "          'cartons': 19,\n",
              "          'pot': 21,\n",
              "          'bougies': 16,\n",
              "          'emballage': 4,\n",
              "          'usine': 16,\n",
              "          'balaie': 32,\n",
              "          'asiatique': 304,\n",
              "          'les': 1676,\n",
              "          'cycliste': 134,\n",
              "          'conducteur': 17,\n",
              "          'voiture': 286,\n",
              "          'penché': 32,\n",
              "          'herbe': 417,\n",
              "          'bambins': 2,\n",
              "          'place': 77,\n",
              "          'véhicule': 65,\n",
              "          'étrange': 18,\n",
              "          'observent': 19,\n",
              "          'argenté': 14,\n",
              "          'aide': 68,\n",
              "          'déplace': 18,\n",
              "          'mari': 9,\n",
              "          'nouveau': 30,\n",
              "          'mariée': 47,\n",
              "          'belle': 74,\n",
              "          'mcdonald': 2,\n",
              "          'gamecube': 1,\n",
              "          'jouer': 153,\n",
              "          'garçon': 1675,\n",
              "          'balle': 364,\n",
              "          'plage': 507,\n",
              "          'bord': 268,\n",
              "          'ébroue': 7,\n",
              "          'parc': 351,\n",
              "          'barbecue': 44,\n",
              "          'chemisier': 43,\n",
              "          'autour': 377,\n",
              "          'bras': 207,\n",
              "          'pose': 179,\n",
              "          'soleil': 371,\n",
              "          'picnic': 1,\n",
              "          'tables': 42,\n",
              "          'extérieur': 252,\n",
              "          'mangent': 58,\n",
              "          ' ': 43,\n",
              "          'ballons': 66,\n",
              "          'taekwondo': 1,\n",
              "          'compétition': 71,\n",
              "          'lors': 612,\n",
              "          'pied': 87,\n",
              "          'coup': 68,\n",
              "          'donnant': 37,\n",
              "          'dessus': 545,\n",
              "          'saute': 540,\n",
              "          'eau': 1041,\n",
              "          'jette': 42,\n",
              "          'papier': 93,\n",
              "          'morceau': 66,\n",
              "          'lire': 58,\n",
              "          'essayant': 82,\n",
              "          'protéger': 14,\n",
              "          'tente': 168,\n",
              "          'descendent': 33,\n",
              "          'pierre': 132,\n",
              "          'mur': 384,\n",
              "          'fabrique': 7,\n",
              "          'salopette': 27,\n",
              "          'bûche': 3,\n",
              "          'costume': 280,\n",
              "          'messieurs': 8,\n",
              "          'autres': 431,\n",
              "          'dépasse': 3,\n",
              "          'plastique': 86,\n",
              "          'tenant': 750,\n",
              "          'réchaud': 3,\n",
              "          'hotdogs': 4,\n",
              "          'griller': 18,\n",
              "          'fait': 1027,\n",
              "          'olive': 4,\n",
              "          'fort': 10,\n",
              "          'nus': 86,\n",
              "          'pieds': 109,\n",
              "          'neige': 460,\n",
              "          'court': 469,\n",
              "          'feu': 89,\n",
              "          'attend': 85,\n",
              "          'vendre': 35,\n",
              "          'illustrations': 1,\n",
              "          'skis': 25,\n",
              "          'assure': 3,\n",
              "          'rocher': 136,\n",
              "          'ascension': 7,\n",
              "          'alpinistes': 7,\n",
              "          'sept': 33,\n",
              "          'équilibre': 70,\n",
              "          'poutre': 22,\n",
              "          'plane': 5,\n",
              "          'gymnaste': 32,\n",
              "          'souple': 6,\n",
              "          'corps': 14,\n",
              "          'caoutchouc': 16,\n",
              "          'piscine': 244,\n",
              "          'atv': 2,\n",
              "          'jouet': 148,\n",
              "          'pousse': 75,\n",
              "          'contre-bas': 1,\n",
              "          'jumelle': 2,\n",
              "          'coupe-vent': 6,\n",
              "          'avion': 54,\n",
              "          'qui': 949,\n",
              "          'objet': 120,\n",
              "          'tuyau': 37,\n",
              "          'joue': 808,\n",
              "          'supermarché': 30,\n",
              "          'chariot': 112,\n",
              "          'heureux': 29,\n",
              "          'visiblement': 2,\n",
              "          'posent': 114,\n",
              "          'chiens': 407,\n",
              "          'attraper': 150,\n",
              "          'point': 110,\n",
              "          'restaurant': 193,\n",
              "          'visage': 203,\n",
              "          'partie': 30,\n",
              "          'couvrant': 9,\n",
              "          'main': 455,\n",
              "          'verte': 275,\n",
              "          'type': 31,\n",
              "          'vers': 401,\n",
              "          'prenant': 113,\n",
              "          'randonneurs': 31,\n",
              "          'création': 5,\n",
              "          'nouvelle': 10,\n",
              "          'crâner': 1,\n",
              "          'nature': 13,\n",
              "          'camping': 19,\n",
              "          'voyage': 10,\n",
              "          'adulte': 88,\n",
              "          'fils': 59,\n",
              "          'âgé': 199,\n",
              "          'père': 78,\n",
              "          'carte': 21,\n",
              "          'lit': 189,\n",
              "          'barbu': 68,\n",
              "          'voyageur': 3,\n",
              "          'entourée': 34,\n",
              "          'étendue': 56,\n",
              "          'canard': 16,\n",
              "          'coucou': 2,\n",
              "          'dit': 27,\n",
              "          'poussette': 54,\n",
              "          'bébé': 264,\n",
              "          'couple': 270,\n",
              "          'stationnement': 8,\n",
              "          'côté': 909,\n",
              "          'immeuble': 55,\n",
              "          'quelques': 134,\n",
              "          'gelé': 4,\n",
              "          'étang': 30,\n",
              "          'glace': 116,\n",
              "          'percer': 3,\n",
              "          'imposants': 2,\n",
              "          'beiges': 8,\n",
              "          'pics': 1,\n",
              "          'grimper': 6,\n",
              "          'pré': 8,\n",
              "          'chemin': 179,\n",
              "          'publique': 28,\n",
              "          'sécurité': 78,\n",
              "          'ignorant': 1,\n",
              "          'pelletées': 2,\n",
              "          'mariage': 48,\n",
              "          'gâteau': 53,\n",
              "          'derrière': 510,\n",
              "          'mouillé': 22,\n",
              "          'marché': 166,\n",
              "          'récolte': 4,\n",
              "          'villageois': 4,\n",
              "          'shirt': 1322,\n",
              "          '-': 2457,\n",
              "          't': 1336,\n",
              "          'chanteur': 27,\n",
              "          'approche': 20,\n",
              "          'bondé': 31,\n",
              "          'concert': 76,\n",
              "          'skateboard': 207,\n",
              "          'kayak': 38,\n",
              "          'côtés': 25,\n",
              "          'assises': 346,\n",
              "          'travaillent': 140,\n",
              "          'y': 276,\n",
              "          'construction': 63,\n",
              "          'chantier': 58,\n",
              "          'publicitaire': 21,\n",
              "          'panneau': 87,\n",
              "          'discuter': 23,\n",
              "          'couleurs': 67,\n",
              "          'spectre': 1,\n",
              "          'drapeaux': 65,\n",
              "          'agitant': 20,\n",
              "          'poisson': 53,\n",
              "          'préparer': 20,\n",
              "          'regardent': 539,\n",
              "          'âgés': 55,\n",
              "          'chanson': 18,\n",
              "          'chanter': 20,\n",
              "          'fluide': 2,\n",
              "          'jupe': 77,\n",
              "          'débardeur': 144,\n",
              "          'marches': 120,\n",
              "          'attrape': 47,\n",
              "          'labrador': 5,\n",
              "          'brun': 426,\n",
              "          'bâton': 109,\n",
              "          'objectif': 123,\n",
              "          'concentre': 10,\n",
              "          'hockey': 96,\n",
              "          'but': 59,\n",
              "          'gardien': 33,\n",
              "          'art': 59,\n",
              "          'sculpture': 37,\n",
              "          'bâtiment': 590,\n",
              "          'cour': 86,\n",
              "          'garde-corps': 3,\n",
              "          'proximité': 85,\n",
              "          'agenouillée': 18,\n",
              "          'alors': 94,\n",
              "          'herbeux': 12,\n",
              "          'champ': 238,\n",
              "          'tiennent': 145,\n",
              "          'gratte-ciel': 3,\n",
              "          'face': 194,\n",
              "          'local': 15,\n",
              "          'promène': 77,\n",
              "          'fruits': 90,\n",
              "          'coté': 28,\n",
              "          'table': 480,\n",
              "          'noirs': 211,\n",
              "          'cheveux': 536,\n",
              "          'blond': 94,\n",
              "          'nourriture': 240,\n",
              "          'mange': 61,\n",
              "          'électrique': 45,\n",
              "          'bas': 129,\n",
              "          'directement': 3,\n",
              "          'presque': 12,\n",
              "          'frappe': 65,\n",
              "          'molle': 3,\n",
              "          'couleur': 110,\n",
              "          'urbaine': 20,\n",
              "          'zone': 115,\n",
              "          'béton': 87,\n",
              "          'lisser': 1,\n",
              "          'bon': 26,\n",
              "          'couverture': 58,\n",
              "          'allongée': 53,\n",
              "          'soirée': 34,\n",
              "          'pont': 129,\n",
              "          'solitaire': 34,\n",
              "          'marche': 585,\n",
              "          'verts': 66,\n",
              "          'haricots': 3,\n",
              "          'montagne': 180,\n",
              "          'rebord': 23,\n",
              "          'reposent': 19,\n",
              "          'arbres': 176,\n",
              "          'couverte': 26,\n",
              "          'colline': 105,\n",
              "          'très': 279,\n",
              "          'passerelle': 28,\n",
              "          'traversent': 64,\n",
              "          'pneumatiques': 4,\n",
              "          'bateaux': 22,\n",
              "          'petites': 62,\n",
              "          'blonde': 195,\n",
              "          'bambou': 8,\n",
              "          'instrument': 70,\n",
              "          'jouant': 740,\n",
              "          'chaise': 130,\n",
              "          'gris': 286,\n",
              "          'fréquentée': 78,\n",
              "          'monte': 80,\n",
              "          'briques': 108,\n",
              "          'téléphone': 246,\n",
              "          'ans': 8,\n",
              "          '30': 2,\n",
              "          'plus': 127,\n",
              "          'bus': 139,\n",
              "          'piétons': 35,\n",
              "          'passage': 42,\n",
              "          'marchent': 412,\n",
              "          'nouilles': 5,\n",
              "          'océan': 185,\n",
              "          'tête': 289,\n",
              "          'plein': 166,\n",
              "          'bol': 33,\n",
              "          'trou': 44,\n",
              "          'eux': 192,\n",
              "          'trop': 6,\n",
              "          'beaucoup': 160,\n",
              "          'ils': 135,\n",
              "          'car': 10,\n",
              "          'sourire': 30,\n",
              "          'ont': 92,\n",
              "          'baignoire': 16,\n",
              "          'forestière': 6,\n",
              "          'individus': 22,\n",
              "          'rayé': 147,\n",
              "          'rose': 443,\n",
              "          \"quelqu'\": 155,\n",
              "          'dort': 76,\n",
              "          'caméra': 60,\n",
              "          'attentivement': 26,\n",
              "          'tribale': 2,\n",
              "          'robe': 369,\n",
              "          'africaine': 18,\n",
              "          'tribu': 6,\n",
              "          'membre': 19,\n",
              "          'entraînement': 20,\n",
              "          'tapis': 76,\n",
              "          'fourreau': 1,\n",
              "          'épée': 19,\n",
              "          'prend': 236,\n",
              "          'samouraï': 2,\n",
              "          'guerrier': 3,\n",
              "          'bondée': 33,\n",
              "          'rail': 8,\n",
              "          'rocheuse': 65,\n",
              "          'rivière': 139,\n",
              "          'travers': 163,\n",
              "          'opposé': 7,\n",
              "          'tournée': 1,\n",
              "          'tourné': 11,\n",
              "          'éclairée': 25,\n",
              "          'métallique': 78,\n",
              "          'agent': 27,\n",
              "          'lavent': 8,\n",
              "          'pourpre': 9,\n",
              "          'accroupi': 37,\n",
              "          'maison': 130,\n",
              "          'clair': 78,\n",
              "          'droite': 53,\n",
              "          'boule': 58,\n",
              "          'sol': 233,\n",
              "          'il': 670,\n",
              "          'planche': 145,\n",
              "          'tour': 52,\n",
              "          'planchiste': 2,\n",
              "          'rient': 34,\n",
              "          'serrer': 3,\n",
              "          'partir': 13,\n",
              "          'tend': 20,\n",
              "          'bouteille': 62,\n",
              "          'walkie': 3,\n",
              "          'talkie': 3,\n",
              "          'communique': 3,\n",
              "          'pilote': 66,\n",
              "          'voit': 33,\n",
              "          'on': 50,\n",
              "          'comme': 73,\n",
              "          'pagayant': 8,\n",
              "          'nattes': 7,\n",
              "          'pulls': 6,\n",
              "          'repas': 75,\n",
              "          'acier': 11,\n",
              "          'ouvriers': 147,\n",
              "          'pâte': 19,\n",
              "          'joyeusement': 26,\n",
              "          'mélange': 12,\n",
              "          'ensoleillée': 94,\n",
              "          'journée': 208,\n",
              "          'boue': 49,\n",
              "          'ballon': 457,\n",
              "          'voyages': 1,\n",
              "          'brochure': 4,\n",
              "          'riant': 33,\n",
              "          'discutant': 42,\n",
              "          'courant': 233,\n",
              "          'plongeoir': 12,\n",
              "          'sauter': 76,\n",
              "          'claire': 14,\n",
              "          'fruit': 7,\n",
              "          'mangeant': 77,\n",
              "          'bassine': 5,\n",
              "          'détend': 11,\n",
              "          'arrêt': 29,\n",
              "          'dormir': 21,\n",
              "          'arbre': 222,\n",
              "          'jean': 291,\n",
              "          'conduite': 3,\n",
              "          'endormi': 34,\n",
              "          'sous': 378,\n",
              "          'crêpe': 4,\n",
              "          'cuisine': 169,\n",
              "          'alarme': 1,\n",
              "          'réagissent': 2,\n",
              "          'pompiers': 54,\n",
              "          'camions': 16,\n",
              "          'rivage': 54,\n",
              "          'rouges': 245,\n",
              "          'bleus': 138,\n",
              "          'travailler': 36,\n",
              "          'gilets': 91,\n",
              "          'casques': 101,\n",
              "          'magazines': 13,\n",
              "          'coloré': 47,\n",
              "          'collage': 1,\n",
              "          'vendeur': 60,\n",
              "          'lui': 300,\n",
              "          'yeux': 78,\n",
              "          'ses': 552,\n",
              "          'farine': 4,\n",
              "          'retire': 7,\n",
              "          'apprenti': 1,\n",
              "          'pendant': 245,\n",
              "          'boulanger': 2,\n",
              "          'vieux': 101,\n",
              "          'boulangerie': 6,\n",
              "          'tropicale': 6,\n",
              "          'ombre': 43,\n",
              "          'nu': 147,\n",
              "          'torse': 135,\n",
              "          'bain': 165,\n",
              "          'short': 271,\n",
              "          'surplombe': 6,\n",
              "          'skieur': 56,\n",
              "          'terre': 325,\n",
              "          'monticule': 28,\n",
              "          'juste': 43,\n",
              "          'gauche': 70,\n",
              "          'serré': 6,\n",
              "          'virage': 37,\n",
              "          'prennent': 75,\n",
              "          'course': 347,\n",
              "          'coureurs': 45,\n",
              "          'tas': 86,\n",
              "          'avant': 99,\n",
              "          'penche': 57,\n",
              "          'canne': 55,\n",
              "          'opération': 18,\n",
              "          'effectuent': 9,\n",
              "          'bleues': 93,\n",
              "          'blouses': 13,\n",
              "          'infirmières': 9,\n",
              "          'médecin': 15,\n",
              "          'doberman': 1,\n",
              "          'pourchasse': 4,\n",
              "          'laineux': 1,\n",
              "          'piste': 176,\n",
              "          'bowling': 60,\n",
              "          'rouler': 13,\n",
              "          'avoir': 55,\n",
              "          'après': 162,\n",
              "          'là': 7,\n",
              "          'rochers': 81,\n",
              "          'âne': 15,\n",
              "          'magnifique': 21,\n",
              "          'chevauchant': 24,\n",
              "          'ridé': 1,\n",
              "          'canapé': 100,\n",
              "          'sieste': 36,\n",
              "          'javelot': 7,\n",
              "          'lancer': 76,\n",
              "          'maillot': 310,\n",
              "          'montgolfières': 6,\n",
              "          'regardant': 607,\n",
              "          'épaule': 35,\n",
              "          'magazine': 20,\n",
              "          'allumer': 3,\n",
              "          'accroupissent': 1,\n",
              "          'commercial': 25,\n",
              "          'centre': 61,\n",
              "          'sombre': 52,\n",
              "          'pièce': 140,\n",
              "          'mousse': 13,\n",
              "          'couvert': 50,\n",
              "          'bateau': 252,\n",
              "          'fête': 118,\n",
              "          'dizaines': 4,\n",
              "          'paille': 33,\n",
              "          'cowboy': 29,\n",
              "          'donne': 69,\n",
              "          'bikini': 54,\n",
              "          'colorés': 65,\n",
              "          'tubes': 6,\n",
              "          'toboggan': 71,\n",
              "          'prêt': 28,\n",
              "          'air': 659,\n",
              "          'tout-petit': 34,\n",
              "          'plongée': 14,\n",
              "          'combinaison': 99,\n",
              "          'rurale': 8,\n",
              "          'camion': 148,\n",
              "          'voyageant': 4,\n",
              "          'hamburgers': 4,\n",
              "          'chefs': 16,\n",
              "          'grimaces': 11,\n",
              "          'étincelles': 4,\n",
              "          'volent': 14,\n",
              "          'où': 161,\n",
              "          'clôturée': 16,\n",
              "          'croix': 13,\n",
              "          'elles': 99,\n",
              "          'fer': 25,\n",
              "          'voie': 46,\n",
              "          'deneiger': 1,\n",
              "          'travaillant': 149,\n",
              "          'contenu': 8,\n",
              "          'chevaux': 59,\n",
              "          'wagon': 21,\n",
              "          'réfléchissants': 7,\n",
              "          'travailleurs': 21,\n",
              "          'beetle': 1,\n",
              "          'volkswagen': 6,\n",
              "          'rustique': 6,\n",
              "          'classique': 7,\n",
              "          'métal': 44,\n",
              "          'armature': 1,\n",
              "          'assemble': 3,\n",
              "          'a': 602,\n",
              "          'ponton': 10,\n",
              "          'sans': 70,\n",
              "          'matériel': 55,\n",
              "          'répare': 23,\n",
              "          'cils': 1,\n",
              "          'ces': 32,\n",
              "          'mascara': 4,\n",
              "          'applique': 4,\n",
              "          'intérieur': 139,\n",
              "          'escalade': 111,\n",
              "          'trotoir': 1,\n",
              "          'garés': 14,\n",
              "          'scooters': 7,\n",
              "          'atterir': 1,\n",
              "          'prépare': 96,\n",
              "          'régional': 1,\n",
              "          'hélicoptère': 10,\n",
              "          'échaffaudage': 1,\n",
              "          'positionne': 3,\n",
              "          'diner': 2,\n",
              "          'contenant': 14,\n",
              "          'rassemblé': 2,\n",
              "          'quatorze': 1,\n",
              "          'gonflable': 32,\n",
              "          'adolescent': 53,\n",
              "          'famille': 107,\n",
              "          'aliments': 22,\n",
              "          'frire': 7,\n",
              "          'vieille': 67,\n",
              "          'plume': 6,\n",
              "          'coiffe': 10,\n",
              "          'flamboyante': 1,\n",
              "          'approchés': 2,\n",
              "          'skieurs': 16,\n",
              "          'sommet': 91,\n",
              "          'document': 12,\n",
              "          'rempli': 75,\n",
              "          'elle': 343,\n",
              "          'rues': 38,\n",
              "          'intersection': 18,\n",
              "          'genoux': 87,\n",
              "          'mains': 181,\n",
              "          'serre': 15,\n",
              "          'corsage': 1,\n",
              "          'violet': 136,\n",
              "          'promenade': 42,\n",
              "          'pêchent': 7,\n",
              "          'mère': 79,\n",
              "          'palettes': 2,\n",
              "          'jeu': 169,\n",
              "          'six': 80,\n",
              "          'rie': 1,\n",
              "          'jerrican': 2,\n",
              "          'antique': 2,\n",
              "          'automobile': 7,\n",
              "          'moteur': 19,\n",
              "          'poney': 7,\n",
              "          'menée': 1,\n",
              "          'charette': 1,\n",
              "          'tirent': 22,\n",
              "          'falaise': 64,\n",
              "          'descendant': 54,\n",
              "          'repose': 36,\n",
              "          'craie': 16,\n",
              "          'dessin': 17,\n",
              "          'phrase': 1,\n",
              "          'être': 153,\n",
              "          'semble': 135,\n",
              "          'frapper': 87,\n",
              "          'semblant': 15,\n",
              "          'adultes': 136,\n",
              "          'vaste': 20,\n",
              "          'plateforme': 7,\n",
              "          'depuis': 72,\n",
              "          'coudre': 24,\n",
              "          'machine': 108,\n",
              "          'méticuleusement': 1,\n",
              "          'levé': 6,\n",
              "          'bland': 1,\n",
              "          'poivrons': 1,\n",
              "          'vendant': 52,\n",
              "          'chaine': 1,\n",
              "          'agée': 1,\n",
              "          'bulles': 55,\n",
              "          '4': 6,\n",
              "          'soufflé': 2,\n",
              "          'obstable': 1,\n",
              "          'tunnel': 39,\n",
              "          'sort': 45,\n",
              "          'poussière': 24,\n",
              "          'courent': 200,\n",
              "          'sautant': 247,\n",
              "          'fleuri': 10,\n",
              "          'imprimé': 11,\n",
              "          'devout': 1,\n",
              "          'colorées': 33,\n",
              "          'casquettes': 22,\n",
              "          'rangée': 36,\n",
              "          'barrière': 38,\n",
              "          'sourient': 76,\n",
              "          'moto': 178,\n",
              "          'sortie': 16,\n",
              "          'enlever': 8,\n",
              "          'pile': 22,\n",
              "          'pliante': 11,\n",
              "          'jour': 27,\n",
              "          'tombée': 12,\n",
              "          'fleur': 20,\n",
              "          'pétales': 5,\n",
              "          'souffle': 18,\n",
              "          'bruns': 97,\n",
              "          'quad': 28,\n",
              "          'airs': 85,\n",
              "          'volant': 40,\n",
              "          'foncés': 77,\n",
              "          'spatule': 6,\n",
              "          'poêle': 8,\n",
              "          'retournent': 2,\n",
              "          'plan': 168,\n",
              "          'vache': 30,\n",
              "          'entouré': 69,\n",
              "          'champs': 8,\n",
              "          'embrassant': 23,\n",
              "          'arrivée': 16,\n",
              "          'attendant': 87,\n",
              "          'jetée': 31,\n",
              "          'approchant': 8,\n",
              "          'parlant': 159,\n",
              "          'cardigan': 2,\n",
              "          'sandales': 41,\n",
              "          'micro': 191,\n",
              "          'chante': 125,\n",
              "          'forme': 77,\n",
              "          'éléphant': 14,\n",
              "          'mecs': 5,\n",
              "          'three': 1,\n",
              "          'capot': 10,\n",
              "          'mexicain': 7,\n",
              "          'photo': 680,\n",
              "          'rousse': 45,\n",
              "          'jaunes': 102,\n",
              "          'types': 12,\n",
              "          'différents': 26,\n",
              "          'rassemble': 11,\n",
              "          'renversé': 7,\n",
              "          'pleurant': 3,\n",
              "          'terrain': 313,\n",
              "          'foot': 81,\n",
              "          'congélateur': 1,\n",
              "          'mec': 7,\n",
              "          'tabourets': 5,\n",
              "          'sens': 8,\n",
              "          'mauvais': 2,\n",
              "          'étalé': 1,\n",
              "          'américain': 138,\n",
              "          'coline': 1,\n",
              "          'coure': 2,\n",
              "          'jeans': 21,\n",
              "          'pouces': 5,\n",
              "          'escalator': 25,\n",
              "          'adverse': 31,\n",
              "          'joueur': 315,\n",
              "          'coéquipiers': 7,\n",
              "          'uns': 33,\n",
              "          'porté': 5,\n",
              "          'football': 399,\n",
              "          'désert': 39,\n",
              "          'construisent': 7,\n",
              "          'bandeaux': 5,\n",
              "          'maquillage': 18,\n",
              "          'ornées': 1,\n",
              "          'amies': 7,\n",
              "          'bandoulière': 10,\n",
              "          'dame': 66,\n",
              "          'blouson': 23,\n",
              "          'porche': 12,\n",
              "          'étant': 73,\n",
              "          'bizarres': 2,\n",
              "          'vêtements': 256,\n",
              "          'funky': 1,\n",
              "          'habits': 10,\n",
              "          'opposée': 3,\n",
              "          'équipe': 195,\n",
              "          'arrêter': 5,\n",
              "          'long': 317,\n",
              "          'tablier': 70,\n",
              "          'public': 121,\n",
              "          'frisbee': 90,\n",
              "          'marron': 332,\n",
              "          'tennis': 193,\n",
              "          'joueurs': 150,\n",
              "          'représentation': 5,\n",
              "          'enflammées': 2,\n",
              "          'torches': 5,\n",
              "          'jongleurs': 1,\n",
              "          'chaussures': 107,\n",
              "          'galets': 7,\n",
              "          'grimace': 18,\n",
              "          'gap': 4,\n",
              "          'casquette': 272,\n",
              "          'accroche': 21,\n",
              "          'respiration': 1,\n",
              "          'retient': 3,\n",
              "          'speedo': 5,\n",
              "          'scooter': 36,\n",
              "          'buvant': 68,\n",
              "          'cartes': 23,\n",
              "          'light': 4,\n",
              "          'coca': 11,\n",
              "          'ribbon': 2,\n",
              "          'blue': 4,\n",
              "          'pabst': 2,\n",
              "          'rencontre': 7,\n",
              "          'apprécient': 13,\n",
              "          'escalader': 13,\n",
              "          'alpiniste': 21,\n",
              "          'grenouille': 3,\n",
              "          'journal': 80,\n",
              "          'tournesol': 2,\n",
              "          'graines': 3,\n",
              "          'oiseau': 48,\n",
              "          'va': 36,\n",
              "          'travaux': 30,\n",
              "          'toit': 85,\n",
              "          \"c'\": 44,\n",
              "          'véhicules': 20,\n",
              "          'campeur': 1,\n",
              "          'appareil': 151,\n",
              "          'vagues': 53,\n",
              "          'musulmane': 2,\n",
              "          'tenue': 418,\n",
              "          'pelouse': 124,\n",
              "          'courir': 37,\n",
              "          'surélevée': 8,\n",
              "          'plate': 25,\n",
              "          'jogging': 28,\n",
              "          'traverse': 78,\n",
              "          'ouverte': 56,\n",
              "          'gueule': 140,\n",
              "          'extérieure': 15,\n",
              "          'nageant': 36,\n",
              "          'souriante': 39,\n",
              "          'entretien': 12,\n",
              "          'faire': 220,\n",
              "          'navire': 10,\n",
              "          'poirier': 2,\n",
              "          'réparations': 7,\n",
              "          'nettoie': 34,\n",
              "          'agenouillé': 16,\n",
              "          'achève': 2,\n",
              "          'ouvrier': 90,\n",
              "          'snowboard': 39,\n",
              "          'golf': 42,\n",
              "          'trophée': 7,\n",
              "          ...}),\n",
              " 'itos': ['<unk>',\n",
              "  '<pad>',\n",
              "  '<SOS>',\n",
              "  '<EOS>',\n",
              "  'un',\n",
              "  '.',\n",
              "  'une',\n",
              "  'de',\n",
              "  'en',\n",
              "  \"d'\",\n",
              "  'dans',\n",
              "  'sur',\n",
              "  'homme',\n",
              "  'et',\n",
              "  'des',\n",
              "  'avec',\n",
              "  'la',\n",
              "  'à',\n",
              "  ',',\n",
              "  'femme',\n",
              "  \"l'\",\n",
              "  'deux',\n",
              "  'le',\n",
              "  'est',\n",
              "  '-',\n",
              "  'debout',\n",
              "  'se',\n",
              "  'personnes',\n",
              "  'sont',\n",
              "  'jeune',\n",
              "  'au',\n",
              "  'tandis',\n",
              "  'devant',\n",
              "  'hommes',\n",
              "  'fille',\n",
              "  'du',\n",
              "  'groupe',\n",
              "  'les',\n",
              "  'garçon',\n",
              "  'assis',\n",
              "  'chien',\n",
              "  'son',\n",
              "  'rue',\n",
              "  'rouge',\n",
              "  \"qu'\",\n",
              "  'noir',\n",
              "  'portant',\n",
              "  't',\n",
              "  'shirt',\n",
              "  'blanc',\n",
              "  'pour',\n",
              "  'gens',\n",
              "  'trois',\n",
              "  'train',\n",
              "  'bleu',\n",
              "  'eau',\n",
              "  'femmes',\n",
              "  'fait',\n",
              "  'enfant',\n",
              "  'enfants',\n",
              "  'qui',\n",
              "  'sa',\n",
              "  'côté',\n",
              "  'tient',\n",
              "  'par',\n",
              "  'autre',\n",
              "  'regarde',\n",
              "  'que',\n",
              "  'petit',\n",
              "  'joue',\n",
              "  'près',\n",
              "  \"s'\",\n",
              "  'personne',\n",
              "  'tenant',\n",
              "  'vêtu',\n",
              "  'jouant',\n",
              "  'photo',\n",
              "  'il',\n",
              "  'jaune',\n",
              "  'chemise',\n",
              "  'air',\n",
              "  'jeunes',\n",
              "  'vélo',\n",
              "  'jouent',\n",
              "  'petite',\n",
              "  'lors',\n",
              "  'regardant',\n",
              "  'a',\n",
              "  'dehors',\n",
              "  'bâtiment',\n",
              "  'marche',\n",
              "  'blanche',\n",
              "  'lunettes',\n",
              "  'veste',\n",
              "  'ses',\n",
              "  'assise',\n",
              "  'trottoir',\n",
              "  'dessus',\n",
              "  'faisant',\n",
              "  'saute',\n",
              "  'regardent',\n",
              "  'cheveux',\n",
              "  'tout',\n",
              "  'foule',\n",
              "  'marchant',\n",
              "  'derrière',\n",
              "  'vert',\n",
              "  'plage',\n",
              "  'bleue',\n",
              "  'porte',\n",
              "  'table',\n",
              "  'court',\n",
              "  'neige',\n",
              "  'ballon',\n",
              "  'main',\n",
              "  'quelque',\n",
              "  'plusieurs',\n",
              "  'rose',\n",
              "  'chose',\n",
              "  'autres',\n",
              "  'filles',\n",
              "  'grand',\n",
              "  'arrière-plan',\n",
              "  'brun',\n",
              "  'tenue',\n",
              "  'herbe',\n",
              "  'orange',\n",
              "  'marchent',\n",
              "  'aux',\n",
              "  'quatre',\n",
              "  'chiens',\n",
              "  'chapeau',\n",
              "  '\"',\n",
              "  'vers',\n",
              "  'football',\n",
              "  'ville',\n",
              "  'noire',\n",
              "  'mur',\n",
              "  'sous',\n",
              "  'autour',\n",
              "  'leurs',\n",
              "  'soleil',\n",
              "  'robe',\n",
              "  'balle',\n",
              "  'font',\n",
              "  'guitare',\n",
              "  'garçons',\n",
              "  'parc',\n",
              "  'course',\n",
              "  'assises',\n",
              "  'sac',\n",
              "  'bois',\n",
              "  'elle',\n",
              "  'ensemble',\n",
              "  'marron',\n",
              "  'scène',\n",
              "  'terre',\n",
              "  'long',\n",
              "  'joueur',\n",
              "  'gars',\n",
              "  'terrain',\n",
              "  'banc',\n",
              "  'maillot',\n",
              "  'vêtue',\n",
              "  'asiatique',\n",
              "  'lui',\n",
              "  'haut',\n",
              "  'jean',\n",
              "  'pantalon',\n",
              "  'tête',\n",
              "  'gris',\n",
              "  'voiture',\n",
              "  'costume',\n",
              "  'très',\n",
              "  'casque',\n",
              "  'dos',\n",
              "  'y',\n",
              "  'verte',\n",
              "  'casquette',\n",
              "  'short',\n",
              "  'couple',\n",
              "  'bord',\n",
              "  'route',\n",
              "  'bébé',\n",
              "  'cheval',\n",
              "  'gros',\n",
              "  'match',\n",
              "  'vêtements',\n",
              "  'bateau',\n",
              "  'extérieur',\n",
              "  'grande',\n",
              "  'sautant',\n",
              "  'téléphone',\n",
              "  'pendant',\n",
              "  'rouges',\n",
              "  'magasin',\n",
              "  'piscine',\n",
              "  'nourriture',\n",
              "  'sable',\n",
              "  'champ',\n",
              "  'prend',\n",
              "  'milieu',\n",
              "  'courant',\n",
              "  'sol',\n",
              "  'leur',\n",
              "  'arbre',\n",
              "  'faire',\n",
              "  'manteau',\n",
              "  'parle',\n",
              "  'sweat',\n",
              "  'noirs',\n",
              "  'passe',\n",
              "  'journée',\n",
              "  'blancs',\n",
              "  'bras',\n",
              "  'skateboard',\n",
              "  'contre',\n",
              "  'visage',\n",
              "  'vieil',\n",
              "  'courent',\n",
              "  'âgé',\n",
              "  'blonde',\n",
              "  'équipe',\n",
              "  'face',\n",
              "  'souriant',\n",
              "  'restaurant',\n",
              "  'tennis',\n",
              "  'eux',\n",
              "  'micro',\n",
              "  'salle',\n",
              "  'lit',\n",
              "  'sourit',\n",
              "  'portable',\n",
              "  'océan',\n",
              "  'mains',\n",
              "  'montagne',\n",
              "  'chemin',\n",
              "  'pose',\n",
              "  'moto',\n",
              "  'cinq',\n",
              "  'arbres',\n",
              "  'piste',\n",
              "  'fleurs',\n",
              "  'arrière',\n",
              "  'entre',\n",
              "  'cuisine',\n",
              "  'jeu',\n",
              "  'âgée',\n",
              "  'plan',\n",
              "  'tente',\n",
              "  'travaille',\n",
              "  'baseball',\n",
              "  'marché',\n",
              "  'plein',\n",
              "  'bain',\n",
              "  'travers',\n",
              "  'après',\n",
              "  'où',\n",
              "  'beaucoup',\n",
              "  'parlant',\n",
              "  'tenues',\n",
              "  \"quelqu'\",\n",
              "  'vêtus',\n",
              "  'jouer',\n",
              "  'être',\n",
              "  'appareil',\n",
              "  'attraper',\n",
              "  'joueurs',\n",
              "  'nuit',\n",
              "  'travaillant',\n",
              "  'camion',\n",
              "  'jouet',\n",
              "  'nu',\n",
              "  'ou',\n",
              "  'ouvriers',\n",
              "  'rayé',\n",
              "  'planche',\n",
              "  'tiennent',\n",
              "  'débardeur',\n",
              "  'habillé',\n",
              "  'livre',\n",
              "  'rampe',\n",
              "  'gueule',\n",
              "  'pièce',\n",
              "  'travaillent',\n",
              "  'bus',\n",
              "  'intérieur',\n",
              "  'rivière',\n",
              "  'américain',\n",
              "  'blanches',\n",
              "  'bleus',\n",
              "  'adultes',\n",
              "  'musique',\n",
              "  'rocher',\n",
              "  'violet',\n",
              "  'ils',\n",
              "  'semble',\n",
              "  'torse',\n",
              "  'cycliste',\n",
              "  'quelques',\n",
              "  'fenêtre',\n",
              "  'petits',\n",
              "  'pierre',\n",
              "  'ce',\n",
              "  'chaise',\n",
              "  'danse',\n",
              "  'maison',\n",
              "  'bas',\n",
              "  'pont',\n",
              "  'spectateurs',\n",
              "  'lac',\n",
              "  'plus',\n",
              "  'utilise',\n",
              "  'basket',\n",
              "  'chante',\n",
              "  'clôture',\n",
              "  'pelouse',\n",
              "  'objectif',\n",
              "  'corde',\n",
              "  'asiatiques',\n",
              "  'bonnet',\n",
              "  'gilet',\n",
              "  'public',\n",
              "  'marches',\n",
              "  'objet',\n",
              "  'costumes',\n",
              "  'fête',\n",
              "  'balançoire',\n",
              "  'glace',\n",
              "  'stand',\n",
              "  'zone',\n",
              "  'manger',\n",
              "  'montre',\n",
              "  'métro',\n",
              "  'polo',\n",
              "  'posent',\n",
              "  'vague',\n",
              "  'figure',\n",
              "  'prenant',\n",
              "  'allongé',\n",
              "  'chariot',\n",
              "  'sacs',\n",
              "  'escalade',\n",
              "  'regarder',\n",
              "  'couleur',\n",
              "  'point',\n",
              "  'bâton',\n",
              "  'forêt',\n",
              "  'parlent',\n",
              "  'pieds',\n",
              "  'briques',\n",
              "  'machine',\n",
              "  'oranges',\n",
              "  'trouve',\n",
              "  'chaussures',\n",
              "  'famille',\n",
              "  'beige',\n",
              "  'ordinateur',\n",
              "  'colline',\n",
              "  'passent',\n",
              "  'quai',\n",
              "  'base',\n",
              "  'escalier',\n",
              "  'carreaux',\n",
              "  'jaunes',\n",
              "  'longs',\n",
              "  'prendre',\n",
              "  'pull',\n",
              "  'verre',\n",
              "  'casques',\n",
              "  'fontaine',\n",
              "  'peint',\n",
              "  'shirts',\n",
              "  'vieux',\n",
              "  'canapé',\n",
              "  'avant',\n",
              "  'ball',\n",
              "  'combinaison',\n",
              "  'elles',\n",
              "  'enneigée',\n",
              "  'photos',\n",
              "  'bruns',\n",
              "  'noires',\n",
              "  'pente',\n",
              "  'café',\n",
              "  'hockey',\n",
              "  'parapluie',\n",
              "  'parmi',\n",
              "  'prépare',\n",
              "  'tous',\n",
              "  'graffitis',\n",
              "  'alors',\n",
              "  'blond',\n",
              "  'dont',\n",
              "  'ensoleillée',\n",
              "  'sorte',\n",
              "  'bleues',\n",
              "  'papier',\n",
              "  'saut',\n",
              "  'travail',\n",
              "  'utilisant',\n",
              "  'vif',\n",
              "  'moyen',\n",
              "  'ont',\n",
              "  'cette',\n",
              "  'gilets',\n",
              "  'sommet',\n",
              "  'bouche',\n",
              "  'dansent',\n",
              "  'frisbee',\n",
              "  'fruits',\n",
              "  'ouvrier',\n",
              "  'pêche',\n",
              "  'attendent',\n",
              "  'barbe',\n",
              "  'feu',\n",
              "  'loin',\n",
              "  'adulte',\n",
              "  'nombreux',\n",
              "  'numéro',\n",
              "  'attendant',\n",
              "  'béton',\n",
              "  'frapper',\n",
              "  'genoux',\n",
              "  'panneau',\n",
              "  'pied',\n",
              "  'pom',\n",
              "  'statue',\n",
              "  'vêtues',\n",
              "  'bureau',\n",
              "  'cour',\n",
              "  'cyclistes',\n",
              "  'hiver',\n",
              "  'nus',\n",
              "  'plastique',\n",
              "  'tas',\n",
              "  'airs',\n",
              "  'attend',\n",
              "  'descend',\n",
              "  'pleine',\n",
              "  'proximité',\n",
              "  'toit',\n",
              "  'uniforme',\n",
              "  'vue',\n",
              "  'instruments',\n",
              "  'passant',\n",
              "  'dansant',\n",
              "  'essayant',\n",
              "  'ligne',\n",
              "  'lisant',\n",
              "  'posant',\n",
              "  'ciel',\n",
              "  'drapeau',\n",
              "  'feuilles',\n",
              "  'foot',\n",
              "  'pancarte',\n",
              "  'rochers',\n",
              "  'spectacle',\n",
              "  'tire',\n",
              "  'journal',\n",
              "  'montagnes',\n",
              "  'monte',\n",
              "  'portent',\n",
              "  'six',\n",
              "  'uniformes',\n",
              "  'âge',\n",
              "  'événement',\n",
              "  'maillots',\n",
              "  'met',\n",
              "  'mère',\n",
              "  'sautent',\n",
              "  'chaises',\n",
              "  'clair',\n",
              "  'défilé',\n",
              "  'fréquentée',\n",
              "  'métallique',\n",
              "  'père',\n",
              "  'sport',\n",
              "  'sécurité',\n",
              "  'traverse',\n",
              "  'yeux',\n",
              "  'foncés',\n",
              "  'forme',\n",
              "  'grosse',\n",
              "  'jupe',\n",
              "  'mangeant',\n",
              "  'nombreuses',\n",
              "  'place',\n",
              "  'promène',\n",
              "  'structure',\n",
              "  'concert',\n",
              "  'dort',\n",
              "  'lancer',\n",
              "  'sauter',\n",
              "  'ski',\n",
              "  'sourient',\n",
              "  'tapis',\n",
              "  'bière',\n",
              "  'chapeaux',\n",
              "  'classe',\n",
              "  'coin',\n",
              "  'fauteuil',\n",
              "  'pousse',\n",
              "  'prennent',\n",
              "  'rempli',\n",
              "  'repas',\n",
              "  'rodéo',\n",
              "  'belle',\n",
              "  'lance',\n",
              "  'vélos',\n",
              "  'comme',\n",
              "  'habillée',\n",
              "  'jeux',\n",
              "  'sentier',\n",
              "  'voitures',\n",
              "  'écrit',\n",
              "  'étant',\n",
              "  'brune',\n",
              "  'depuis',\n",
              "  'nombre',\n",
              "  'noël',\n",
              "  'panier',\n",
              "  'bar',\n",
              "  'compétition',\n",
              "  'légumes',\n",
              "  'toboggan',\n",
              "  'cow',\n",
              "  'gauche',\n",
              "  'glisse',\n",
              "  'instrument',\n",
              "  'sans',\n",
              "  'tablier',\n",
              "  'équilibre',\n",
              "  'donne',\n",
              "  'entouré',\n",
              "  'aide',\n",
              "  'barbu',\n",
              "  'blonds',\n",
              "  'buvant',\n",
              "  'chantant',\n",
              "  'cigarette',\n",
              "  'coup',\n",
              "  'couleurs',\n",
              "  'cours',\n",
              "  'même',\n",
              "  'paysage',\n",
              "  'pluie',\n",
              "  'skateur',\n",
              "  'vieille',\n",
              "  'apprête',\n",
              "  'ballons',\n",
              "  'bottes',\n",
              "  'boy',\n",
              "  'dame',\n",
              "  'gants',\n",
              "  'morceau',\n",
              "  'pilote',\n",
              "  'surf',\n",
              "  'verts',\n",
              "  'amis',\n",
              "  'artiste',\n",
              "  'battent',\n",
              "  'colorés',\n",
              "  'côte',\n",
              "  'doigt',\n",
              "  'drapeaux',\n",
              "  'frappe',\n",
              "  'grise',\n",
              "  'habillés',\n",
              "  'longue',\n",
              "  'rocheuse',\n",
              "  'véhicule',\n",
              "  'âgées',\n",
              "  'falaise',\n",
              "  'jardin',\n",
              "  'poteau',\n",
              "  'produits',\n",
              "  'traversent',\n",
              "  'bien',\n",
              "  'construction',\n",
              "  'roulant',\n",
              "  'bouteille',\n",
              "  'bâtiments',\n",
              "  'petites',\n",
              "  'préparant',\n",
              "  'rassemblent',\n",
              "  'snowboardeur',\n",
              "  'centre',\n",
              "  'foncé',\n",
              "  'mange',\n",
              "  'martiaux',\n",
              "  'peinture',\n",
              "  'seau',\n",
              "  'surfeur',\n",
              "  'arts',\n",
              "  'bowling',\n",
              "  'caméra',\n",
              "  'courses',\n",
              "  'grands',\n",
              "  'musiciens',\n",
              "  'parler',\n",
              "  'policier',\n",
              "  'robes',\n",
              "  'temps',\n",
              "  'vendeur',\n",
              "  'vitrine',\n",
              "  'art',\n",
              "  'but',\n",
              "  'chevaux',\n",
              "  'fils',\n",
              "  'masque',\n",
              "  'vertes',\n",
              "  'boule',\n",
              "  'capuche',\n",
              "  'chantier',\n",
              "  'couverture',\n",
              "  'lire',\n",
              "  'mangent',\n",
              "  'nage',\n",
              "  'ayant',\n",
              "  'longues',\n",
              "  'pas',\n",
              "  'pavée',\n",
              "  'penche',\n",
              "  'peu',\n",
              "  'préparent',\n",
              "  'traversant',\n",
              "  'collier',\n",
              "  'espace',\n",
              "  'filet',\n",
              "  'lieu',\n",
              "  'ouverte',\n",
              "  'roses',\n",
              "  'skieur',\n",
              "  'échelle',\n",
              "  'étendue',\n",
              "  'avoir',\n",
              "  'bulles',\n",
              "  'canne',\n",
              "  'immeuble',\n",
              "  'manches',\n",
              "  'matériel',\n",
              "  'motocross',\n",
              "  'orchestre',\n",
              "  'premier',\n",
              "  'âgés',\n",
              "  'avion',\n",
              "  'bikini',\n",
              "  'descendant',\n",
              "  'différentes',\n",
              "  'photographe',\n",
              "  'pompiers',\n",
              "  'poussette',\n",
              "  'rayée',\n",
              "  'rivage',\n",
              "  'vend',\n",
              "  'écran',\n",
              "  'adolescent',\n",
              "  'allongée',\n",
              "  'batterie',\n",
              "  'discutent',\n",
              "  'droite',\n",
              "  'gâteau',\n",
              "  'parking',\n",
              "  'poisson',\n",
              "  'remplie',\n",
              "  'tirant',\n",
              "  'vagues',\n",
              "  'mer',\n",
              "  'sombre',\n",
              "  'tour',\n",
              "  'vendant',\n",
              "  'équipes',\n",
              "  'boissons',\n",
              "  'conversation',\n",
              "  'essaie',\n",
              "  'marcher',\n",
              "  'violette',\n",
              "  'coucher',\n",
              "  'couvert',\n",
              "  'laisse',\n",
              "  'on',\n",
              "  'recouverte',\n",
              "  'skate',\n",
              "  'taureau',\n",
              "  'terrasse',\n",
              "  'traverser',\n",
              "  'violon',\n",
              "  'été',\n",
              "  'animée',\n",
              "  'boue',\n",
              "  'cascade',\n",
              "  'clients',\n",
              "  'comptoir',\n",
              "  'coupe',\n",
              "  'station',\n",
              "  'tableau',\n",
              "  'affiche',\n",
              "  'allée',\n",
              "  'argent',\n",
              "  'boisson',\n",
              "  'mariage',\n",
              "  'oiseau',\n",
              "  'pause',\n",
              "  'policiers',\n",
              "  'attrape',\n",
              "  'chauve',\n",
              "  'ciment',\n",
              "  'coloré',\n",
              "  'cordes',\n",
              "  'cravate',\n",
              "  'dents',\n",
              "  'mariée',\n",
              "  'montrant',\n",
              "  'peluche',\n",
              "  'roule',\n",
              "  'vient',\n",
              "  'vole',\n",
              "  'écharpe',\n",
              "  'étudiants',\n",
              "  'joueuse',\n",
              "  'objets',\n",
              "  'pelle',\n",
              "  'promenant',\n",
              "  'randonnée',\n",
              "  'rassemblées',\n",
              "  'roller',\n",
              "  'tasse',\n",
              "  'voie',\n",
              "  'volley',\n",
              "  'coureur',\n",
              "  'coureurs',\n",
              "  'cuir',\n",
              "  'foulard',\n",
              "  'monsieur',\n",
              "  'recouvert',\n",
              "  'rit',\n",
              "  'rousse',\n",
              "  'sort',\n",
              "  'surfe',\n",
              "  'électrique',\n",
              "  'adolescents',\n",
              "  'animal',\n",
              "  'barbecue',\n",
              "  \"c'\",\n",
              "  'conduit',\n",
              "  'jouets',\n",
              "  'miroir',\n",
              "  'métal',\n",
              "  'trou',\n",
              "  ' ',\n",
              "  'chemisier',\n",
              "  'clown',\n",
              "  'hors',\n",
              "  'juste',\n",
              "  'lève',\n",
              "  'marathon',\n",
              "  'membres',\n",
              "  'motard',\n",
              "  'ombre',\n",
              "  'paroi',\n",
              "  'vestes',\n",
              "  'arbitre',\n",
              "  'discutant',\n",
              "  'golf',\n",
              "  'jette',\n",
              "  'ne',\n",
              "  'passage',\n",
              "  'pierres',\n",
              "  'promenade',\n",
              "  'salon',\n",
              "  'stade',\n",
              "  'suspendu',\n",
              "  'tables',\n",
              "  'écouteurs',\n",
              "  'chef',\n",
              "  'fond',\n",
              "  \"jusqu'\",\n",
              "  'manège',\n",
              "  'prairie',\n",
              "  'sandales',\n",
              "  'taille',\n",
              "  'balance',\n",
              "  'boit',\n",
              "  'courts',\n",
              "  'endroit',\n",
              "  'habillées',\n",
              "  'microscope',\n",
              "  'poussant',\n",
              "  'profonde',\n",
              "  'ruelle',\n",
              "  'viande',\n",
              "  'vive',\n",
              "  'volant',\n",
              "  'église',\n",
              "  'épaules',\n",
              "  'accordéon',\n",
              "  'désert',\n",
              "  'effectuant',\n",
              "  'fume',\n",
              "  'peut',\n",
              "  'plantes',\n",
              "  'protection',\n",
              "  'quartier',\n",
              "  'seul',\n",
              "  'snowboard',\n",
              "  'souriante',\n",
              "  'tunnel',\n",
              "  'barrière',\n",
              "  'batte',\n",
              "  'chat',\n",
              "  'kaki',\n",
              "  'kayak',\n",
              "  'mouvement',\n",
              "  'pays',\n",
              "  'raquette',\n",
              "  'représentant',\n",
              "  'rues',\n",
              "  'surplombant',\n",
              "  'toutes',\n",
              "  'accroupi',\n",
              "  'bâtons',\n",
              "  'chinois',\n",
              "  'courir',\n",
              "  'donnant',\n",
              "  'laboratoire',\n",
              "  'multicolore',\n",
              "  'park',\n",
              "  'réunis',\n",
              "  'sauvetage',\n",
              "  'sculpture',\n",
              "  'signe',\n",
              "  'tronc',\n",
              "  'tuyau',\n",
              "  'virage',\n",
              "  'bordée',\n",
              "  'boîte',\n",
              "  'caisse',\n",
              "  'cet',\n",
              "  'colorée',\n",
              "  'cérémonie',\n",
              "  'karaté',\n",
              "  'nageant',\n",
              "  'police',\n",
              "  'profitant',\n",
              "  'rangée',\n",
              "  'repose',\n",
              "  'scooter',\n",
              "  'sieste',\n",
              "  'trampoline',\n",
              "  'travailler',\n",
              "  'télescope',\n",
              "  'va',\n",
              "  'énorme',\n",
              "  'balustrade',\n",
              "  'batteur',\n",
              "  'effectue',\n",
              "  'escaliers',\n",
              "  'fumant',\n",
              "  'grimpe',\n",
              "  'jambe',\n",
              "  'participant',\n",
              "  'piétons',\n",
              "  'produit',\n",
              "  'promènent',\n",
              "  'remorque',\n",
              "  'ruisseau',\n",
              "  'semblent',\n",
              "  'vendre',\n",
              "  'vide',\n",
              "  'volleyball',\n",
              "  'épaule',\n",
              "  'campagne',\n",
              "  'endormi',\n",
              "  'entourée',\n",
              "  'entrée',\n",
              "  'girls',\n",
              "  'gymnase',\n",
              "  'hauts',\n",
              "  'motifs',\n",
              "  'nettoie',\n",
              "  'nettoyant',\n",
              "  'nez',\n",
              "  'rient',\n",
              "  'roulettes',\n",
              "  'soirée',\n",
              "  'soit',\n",
              "  'solitaire',\n",
              "  'tissu',\n",
              "  'touche',\n",
              "  'tout-petit',\n",
              "  'têtes',\n",
              "  'aire',\n",
              "  'barre',\n",
              "  'bol',\n",
              "  'bondée',\n",
              "  'brosse',\n",
              "  'cadre',\n",
              "  'cercle',\n",
              "  'chemises',\n",
              "  'colorées',\n",
              "  'descendent',\n",
              "  'dessous',\n",
              "  'doigts',\n",
              "  'eaux',\n",
              "  'enneigé',\n",
              "  'escaladant',\n",
              "  'examine',\n",
              "  'gardien',\n",
              "  'lumière',\n",
              "  'lumières',\n",
              "  'paille',\n",
              "  'poubelle',\n",
              "  'projet',\n",
              "  'riant',\n",
              "  'roue',\n",
              "  'roux',\n",
              "  'sept',\n",
              "  'uns',\n",
              "  'voici',\n",
              "  'voit',\n",
              "  'écoute',\n",
              "  'balaie',\n",
              "  'certains',\n",
              "  'ces',\n",
              "  'couper',\n",
              "  'façade',\n",
              "  'gare',\n",
              "  'glissant',\n",
              "  'gonflable',\n",
              "  'gymnaste',\n",
              "  'mettant',\n",
              "  'militaire',\n",
              "  'moment',\n",
              "  'pantalons',\n",
              "  'participent',\n",
              "  'penché',\n",
              "  'roulent',\n",
              "  'sale',\n",
              "  'soldats',\n",
              "  'utilisent',\n",
              "  'vin',\n",
              "  'école',\n",
              "  'équipement',\n",
              "  'adverse',\n",
              "  'afro-américain',\n",
              "  'balcon',\n",
              "  'bondé',\n",
              "  'canoë',\n",
              "  'combat',\n",
              "  'coupant',\n",
              "  'divers',\n",
              "  'façon',\n",
              "  'figures',\n",
              "  'fresque',\n",
              "  'gril',\n",
              "  'guitariste',\n",
              "  'haute',\n",
              "  'hautes',\n",
              "  'jambes',\n",
              "  'jetée',\n",
              "  'lanceur',\n",
              "  'lançant',\n",
              "  'manteaux',\n",
              "  'marteau',\n",
              "  'montent',\n",
              "  'obstacle',\n",
              "  'peignant',\n",
              "  'pompier',\n",
              "  'randonneur',\n",
              "  'randonneurs',\n",
              "  'shorts',\n",
              "  'type',\n",
              "  'écoutant',\n",
              "  'éloigne',\n",
              "  'animaux',\n",
              "  'appuie',\n",
              "  'articles',\n",
              "  'bagages',\n",
              "  'cou',\n",
              "  'couché',\n",
              "  'linge',\n",
              "  'livres',\n",
              "  'monde',\n",
              "  'new',\n",
              "  'nouveau',\n",
              "  'oiseaux',\n",
              "  'parcours',\n",
              "  'partie',\n",
              "  'plat',\n",
              "  'queue',\n",
              "  'rassemblés',\n",
              "  'ruban',\n",
              "  'réparer',\n",
              "  'sourire',\n",
              "  'supermarché',\n",
              "  'surface',\n",
              "  'traditionnels',\n",
              "  'travaux',\n",
              "  'vache',\n",
              "  ...],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'<unk>': 0,\n",
              "              '<pad>': 1,\n",
              "              '<SOS>': 2,\n",
              "              '<EOS>': 3,\n",
              "              'un': 4,\n",
              "              '.': 5,\n",
              "              'une': 6,\n",
              "              'de': 7,\n",
              "              'en': 8,\n",
              "              \"d'\": 9,\n",
              "              'dans': 10,\n",
              "              'sur': 11,\n",
              "              'homme': 12,\n",
              "              'et': 13,\n",
              "              'des': 14,\n",
              "              'avec': 15,\n",
              "              'la': 16,\n",
              "              'à': 17,\n",
              "              ',': 18,\n",
              "              'femme': 19,\n",
              "              \"l'\": 20,\n",
              "              'deux': 21,\n",
              "              'le': 22,\n",
              "              'est': 23,\n",
              "              '-': 24,\n",
              "              'debout': 25,\n",
              "              'se': 26,\n",
              "              'personnes': 27,\n",
              "              'sont': 28,\n",
              "              'jeune': 29,\n",
              "              'au': 30,\n",
              "              'tandis': 31,\n",
              "              'devant': 32,\n",
              "              'hommes': 33,\n",
              "              'fille': 34,\n",
              "              'du': 35,\n",
              "              'groupe': 36,\n",
              "              'les': 37,\n",
              "              'garçon': 38,\n",
              "              'assis': 39,\n",
              "              'chien': 40,\n",
              "              'son': 41,\n",
              "              'rue': 42,\n",
              "              'rouge': 43,\n",
              "              \"qu'\": 44,\n",
              "              'noir': 45,\n",
              "              'portant': 46,\n",
              "              't': 47,\n",
              "              'shirt': 48,\n",
              "              'blanc': 49,\n",
              "              'pour': 50,\n",
              "              'gens': 51,\n",
              "              'trois': 52,\n",
              "              'train': 53,\n",
              "              'bleu': 54,\n",
              "              'eau': 55,\n",
              "              'femmes': 56,\n",
              "              'fait': 57,\n",
              "              'enfant': 58,\n",
              "              'enfants': 59,\n",
              "              'qui': 60,\n",
              "              'sa': 61,\n",
              "              'côté': 62,\n",
              "              'tient': 63,\n",
              "              'par': 64,\n",
              "              'autre': 65,\n",
              "              'regarde': 66,\n",
              "              'que': 67,\n",
              "              'petit': 68,\n",
              "              'joue': 69,\n",
              "              'près': 70,\n",
              "              \"s'\": 71,\n",
              "              'personne': 72,\n",
              "              'tenant': 73,\n",
              "              'vêtu': 74,\n",
              "              'jouant': 75,\n",
              "              'photo': 76,\n",
              "              'il': 77,\n",
              "              'jaune': 78,\n",
              "              'chemise': 79,\n",
              "              'air': 80,\n",
              "              'jeunes': 81,\n",
              "              'vélo': 82,\n",
              "              'jouent': 83,\n",
              "              'petite': 84,\n",
              "              'lors': 85,\n",
              "              'regardant': 86,\n",
              "              'a': 87,\n",
              "              'dehors': 88,\n",
              "              'bâtiment': 89,\n",
              "              'marche': 90,\n",
              "              'blanche': 91,\n",
              "              'lunettes': 92,\n",
              "              'veste': 93,\n",
              "              'ses': 94,\n",
              "              'assise': 95,\n",
              "              'trottoir': 96,\n",
              "              'dessus': 97,\n",
              "              'faisant': 98,\n",
              "              'saute': 99,\n",
              "              'regardent': 100,\n",
              "              'cheveux': 101,\n",
              "              'tout': 102,\n",
              "              'foule': 103,\n",
              "              'marchant': 104,\n",
              "              'derrière': 105,\n",
              "              'vert': 106,\n",
              "              'plage': 107,\n",
              "              'bleue': 108,\n",
              "              'porte': 109,\n",
              "              'table': 110,\n",
              "              'court': 111,\n",
              "              'neige': 112,\n",
              "              'ballon': 113,\n",
              "              'main': 114,\n",
              "              'quelque': 115,\n",
              "              'plusieurs': 116,\n",
              "              'rose': 117,\n",
              "              'chose': 118,\n",
              "              'autres': 119,\n",
              "              'filles': 120,\n",
              "              'grand': 121,\n",
              "              'arrière-plan': 122,\n",
              "              'brun': 123,\n",
              "              'tenue': 124,\n",
              "              'herbe': 125,\n",
              "              'orange': 126,\n",
              "              'marchent': 127,\n",
              "              'aux': 128,\n",
              "              'quatre': 129,\n",
              "              'chiens': 130,\n",
              "              'chapeau': 131,\n",
              "              '\"': 132,\n",
              "              'vers': 133,\n",
              "              'football': 134,\n",
              "              'ville': 135,\n",
              "              'noire': 136,\n",
              "              'mur': 137,\n",
              "              'sous': 138,\n",
              "              'autour': 139,\n",
              "              'leurs': 140,\n",
              "              'soleil': 141,\n",
              "              'robe': 142,\n",
              "              'balle': 143,\n",
              "              'font': 144,\n",
              "              'guitare': 145,\n",
              "              'garçons': 146,\n",
              "              'parc': 147,\n",
              "              'course': 148,\n",
              "              'assises': 149,\n",
              "              'sac': 150,\n",
              "              'bois': 151,\n",
              "              'elle': 152,\n",
              "              'ensemble': 153,\n",
              "              'marron': 154,\n",
              "              'scène': 155,\n",
              "              'terre': 156,\n",
              "              'long': 157,\n",
              "              'joueur': 158,\n",
              "              'gars': 159,\n",
              "              'terrain': 160,\n",
              "              'banc': 161,\n",
              "              'maillot': 162,\n",
              "              'vêtue': 163,\n",
              "              'asiatique': 164,\n",
              "              'lui': 165,\n",
              "              'haut': 166,\n",
              "              'jean': 167,\n",
              "              'pantalon': 168,\n",
              "              'tête': 169,\n",
              "              'gris': 170,\n",
              "              'voiture': 171,\n",
              "              'costume': 172,\n",
              "              'très': 173,\n",
              "              'casque': 174,\n",
              "              'dos': 175,\n",
              "              'y': 176,\n",
              "              'verte': 177,\n",
              "              'casquette': 178,\n",
              "              'short': 179,\n",
              "              'couple': 180,\n",
              "              'bord': 181,\n",
              "              'route': 182,\n",
              "              'bébé': 183,\n",
              "              'cheval': 184,\n",
              "              'gros': 185,\n",
              "              'match': 186,\n",
              "              'vêtements': 187,\n",
              "              'bateau': 188,\n",
              "              'extérieur': 189,\n",
              "              'grande': 190,\n",
              "              'sautant': 191,\n",
              "              'téléphone': 192,\n",
              "              'pendant': 193,\n",
              "              'rouges': 194,\n",
              "              'magasin': 195,\n",
              "              'piscine': 196,\n",
              "              'nourriture': 197,\n",
              "              'sable': 198,\n",
              "              'champ': 199,\n",
              "              'prend': 200,\n",
              "              'milieu': 201,\n",
              "              'courant': 202,\n",
              "              'sol': 203,\n",
              "              'leur': 204,\n",
              "              'arbre': 205,\n",
              "              'faire': 206,\n",
              "              'manteau': 207,\n",
              "              'parle': 208,\n",
              "              'sweat': 209,\n",
              "              'noirs': 210,\n",
              "              'passe': 211,\n",
              "              'journée': 212,\n",
              "              'blancs': 213,\n",
              "              'bras': 214,\n",
              "              'skateboard': 215,\n",
              "              'contre': 216,\n",
              "              'visage': 217,\n",
              "              'vieil': 218,\n",
              "              'courent': 219,\n",
              "              'âgé': 220,\n",
              "              'blonde': 221,\n",
              "              'équipe': 222,\n",
              "              'face': 223,\n",
              "              'souriant': 224,\n",
              "              'restaurant': 225,\n",
              "              'tennis': 226,\n",
              "              'eux': 227,\n",
              "              'micro': 228,\n",
              "              'salle': 229,\n",
              "              'lit': 230,\n",
              "              'sourit': 231,\n",
              "              'portable': 232,\n",
              "              'océan': 233,\n",
              "              'mains': 234,\n",
              "              'montagne': 235,\n",
              "              'chemin': 236,\n",
              "              'pose': 237,\n",
              "              'moto': 238,\n",
              "              'cinq': 239,\n",
              "              'arbres': 240,\n",
              "              'piste': 241,\n",
              "              'fleurs': 242,\n",
              "              'arrière': 243,\n",
              "              'entre': 244,\n",
              "              'cuisine': 245,\n",
              "              'jeu': 246,\n",
              "              'âgée': 247,\n",
              "              'plan': 248,\n",
              "              'tente': 249,\n",
              "              'travaille': 250,\n",
              "              'baseball': 251,\n",
              "              'marché': 252,\n",
              "              'plein': 253,\n",
              "              'bain': 254,\n",
              "              'travers': 255,\n",
              "              'après': 256,\n",
              "              'où': 257,\n",
              "              'beaucoup': 258,\n",
              "              'parlant': 259,\n",
              "              'tenues': 260,\n",
              "              \"quelqu'\": 261,\n",
              "              'vêtus': 262,\n",
              "              'jouer': 263,\n",
              "              'être': 264,\n",
              "              'appareil': 265,\n",
              "              'attraper': 266,\n",
              "              'joueurs': 267,\n",
              "              'nuit': 268,\n",
              "              'travaillant': 269,\n",
              "              'camion': 270,\n",
              "              'jouet': 271,\n",
              "              'nu': 272,\n",
              "              'ou': 273,\n",
              "              'ouvriers': 274,\n",
              "              'rayé': 275,\n",
              "              'planche': 276,\n",
              "              'tiennent': 277,\n",
              "              'débardeur': 278,\n",
              "              'habillé': 279,\n",
              "              'livre': 280,\n",
              "              'rampe': 281,\n",
              "              'gueule': 282,\n",
              "              'pièce': 283,\n",
              "              'travaillent': 284,\n",
              "              'bus': 285,\n",
              "              'intérieur': 286,\n",
              "              'rivière': 287,\n",
              "              'américain': 288,\n",
              "              'blanches': 289,\n",
              "              'bleus': 290,\n",
              "              'adultes': 291,\n",
              "              'musique': 292,\n",
              "              'rocher': 293,\n",
              "              'violet': 294,\n",
              "              'ils': 295,\n",
              "              'semble': 296,\n",
              "              'torse': 297,\n",
              "              'cycliste': 298,\n",
              "              'quelques': 299,\n",
              "              'fenêtre': 300,\n",
              "              'petits': 301,\n",
              "              'pierre': 302,\n",
              "              'ce': 303,\n",
              "              'chaise': 304,\n",
              "              'danse': 305,\n",
              "              'maison': 306,\n",
              "              'bas': 307,\n",
              "              'pont': 308,\n",
              "              'spectateurs': 309,\n",
              "              'lac': 310,\n",
              "              'plus': 311,\n",
              "              'utilise': 312,\n",
              "              'basket': 313,\n",
              "              'chante': 314,\n",
              "              'clôture': 315,\n",
              "              'pelouse': 316,\n",
              "              'objectif': 317,\n",
              "              'corde': 318,\n",
              "              'asiatiques': 319,\n",
              "              'bonnet': 320,\n",
              "              'gilet': 321,\n",
              "              'public': 322,\n",
              "              'marches': 323,\n",
              "              'objet': 324,\n",
              "              'costumes': 325,\n",
              "              'fête': 326,\n",
              "              'balançoire': 327,\n",
              "              'glace': 328,\n",
              "              'stand': 329,\n",
              "              'zone': 330,\n",
              "              'manger': 331,\n",
              "              'montre': 332,\n",
              "              'métro': 333,\n",
              "              'polo': 334,\n",
              "              'posent': 335,\n",
              "              'vague': 336,\n",
              "              'figure': 337,\n",
              "              'prenant': 338,\n",
              "              'allongé': 339,\n",
              "              'chariot': 340,\n",
              "              'sacs': 341,\n",
              "              'escalade': 342,\n",
              "              'regarder': 343,\n",
              "              'couleur': 344,\n",
              "              'point': 345,\n",
              "              'bâton': 346,\n",
              "              'forêt': 347,\n",
              "              'parlent': 348,\n",
              "              'pieds': 349,\n",
              "              'briques': 350,\n",
              "              'machine': 351,\n",
              "              'oranges': 352,\n",
              "              'trouve': 353,\n",
              "              'chaussures': 354,\n",
              "              'famille': 355,\n",
              "              'beige': 356,\n",
              "              'ordinateur': 357,\n",
              "              'colline': 358,\n",
              "              'passent': 359,\n",
              "              'quai': 360,\n",
              "              'base': 361,\n",
              "              'escalier': 362,\n",
              "              'carreaux': 363,\n",
              "              'jaunes': 364,\n",
              "              'longs': 365,\n",
              "              'prendre': 366,\n",
              "              'pull': 367,\n",
              "              'verre': 368,\n",
              "              'casques': 369,\n",
              "              'fontaine': 370,\n",
              "              'peint': 371,\n",
              "              'shirts': 372,\n",
              "              'vieux': 373,\n",
              "              'canapé': 374,\n",
              "              'avant': 375,\n",
              "              'ball': 376,\n",
              "              'combinaison': 377,\n",
              "              'elles': 378,\n",
              "              'enneigée': 379,\n",
              "              'photos': 380,\n",
              "              'bruns': 381,\n",
              "              'noires': 382,\n",
              "              'pente': 383,\n",
              "              'café': 384,\n",
              "              'hockey': 385,\n",
              "              'parapluie': 386,\n",
              "              'parmi': 387,\n",
              "              'prépare': 388,\n",
              "              'tous': 389,\n",
              "              'graffitis': 390,\n",
              "              'alors': 391,\n",
              "              'blond': 392,\n",
              "              'dont': 393,\n",
              "              'ensoleillée': 394,\n",
              "              'sorte': 395,\n",
              "              'bleues': 396,\n",
              "              'papier': 397,\n",
              "              'saut': 398,\n",
              "              'travail': 399,\n",
              "              'utilisant': 400,\n",
              "              'vif': 401,\n",
              "              'moyen': 402,\n",
              "              'ont': 403,\n",
              "              'cette': 404,\n",
              "              'gilets': 405,\n",
              "              'sommet': 406,\n",
              "              'bouche': 407,\n",
              "              'dansent': 408,\n",
              "              'frisbee': 409,\n",
              "              'fruits': 410,\n",
              "              'ouvrier': 411,\n",
              "              'pêche': 412,\n",
              "              'attendent': 413,\n",
              "              'barbe': 414,\n",
              "              'feu': 415,\n",
              "              'loin': 416,\n",
              "              'adulte': 417,\n",
              "              'nombreux': 418,\n",
              "              'numéro': 419,\n",
              "              'attendant': 420,\n",
              "              'béton': 421,\n",
              "              'frapper': 422,\n",
              "              'genoux': 423,\n",
              "              'panneau': 424,\n",
              "              'pied': 425,\n",
              "              'pom': 426,\n",
              "              'statue': 427,\n",
              "              'vêtues': 428,\n",
              "              'bureau': 429,\n",
              "              'cour': 430,\n",
              "              'cyclistes': 431,\n",
              "              'hiver': 432,\n",
              "              'nus': 433,\n",
              "              'plastique': 434,\n",
              "              'tas': 435,\n",
              "              'airs': 436,\n",
              "              'attend': 437,\n",
              "              'descend': 438,\n",
              "              'pleine': 439,\n",
              "              'proximité': 440,\n",
              "              'toit': 441,\n",
              "              'uniforme': 442,\n",
              "              'vue': 443,\n",
              "              'instruments': 444,\n",
              "              'passant': 445,\n",
              "              'dansant': 446,\n",
              "              'essayant': 447,\n",
              "              'ligne': 448,\n",
              "              'lisant': 449,\n",
              "              'posant': 450,\n",
              "              'ciel': 451,\n",
              "              'drapeau': 452,\n",
              "              'feuilles': 453,\n",
              "              'foot': 454,\n",
              "              'pancarte': 455,\n",
              "              'rochers': 456,\n",
              "              'spectacle': 457,\n",
              "              'tire': 458,\n",
              "              'journal': 459,\n",
              "              'montagnes': 460,\n",
              "              'monte': 461,\n",
              "              'portent': 462,\n",
              "              'six': 463,\n",
              "              'uniformes': 464,\n",
              "              'âge': 465,\n",
              "              'événement': 466,\n",
              "              'maillots': 467,\n",
              "              'met': 468,\n",
              "              'mère': 469,\n",
              "              'sautent': 470,\n",
              "              'chaises': 471,\n",
              "              'clair': 472,\n",
              "              'défilé': 473,\n",
              "              'fréquentée': 474,\n",
              "              'métallique': 475,\n",
              "              'père': 476,\n",
              "              'sport': 477,\n",
              "              'sécurité': 478,\n",
              "              'traverse': 479,\n",
              "              'yeux': 480,\n",
              "              'foncés': 481,\n",
              "              'forme': 482,\n",
              "              'grosse': 483,\n",
              "              'jupe': 484,\n",
              "              'mangeant': 485,\n",
              "              'nombreuses': 486,\n",
              "              'place': 487,\n",
              "              'promène': 488,\n",
              "              'structure': 489,\n",
              "              'concert': 490,\n",
              "              'dort': 491,\n",
              "              'lancer': 492,\n",
              "              'sauter': 493,\n",
              "              'ski': 494,\n",
              "              'sourient': 495,\n",
              "              'tapis': 496,\n",
              "              'bière': 497,\n",
              "              'chapeaux': 498,\n",
              "              'classe': 499,\n",
              "              'coin': 500,\n",
              "              'fauteuil': 501,\n",
              "              'pousse': 502,\n",
              "              'prennent': 503,\n",
              "              'rempli': 504,\n",
              "              'repas': 505,\n",
              "              'rodéo': 506,\n",
              "              'belle': 507,\n",
              "              'lance': 508,\n",
              "              'vélos': 509,\n",
              "              'comme': 510,\n",
              "              'habillée': 511,\n",
              "              'jeux': 512,\n",
              "              'sentier': 513,\n",
              "              'voitures': 514,\n",
              "              'écrit': 515,\n",
              "              'étant': 516,\n",
              "              'brune': 517,\n",
              "              'depuis': 518,\n",
              "              'nombre': 519,\n",
              "              'noël': 520,\n",
              "              'panier': 521,\n",
              "              'bar': 522,\n",
              "              'compétition': 523,\n",
              "              'légumes': 524,\n",
              "              'toboggan': 525,\n",
              "              'cow': 526,\n",
              "              'gauche': 527,\n",
              "              'glisse': 528,\n",
              "              'instrument': 529,\n",
              "              'sans': 530,\n",
              "              'tablier': 531,\n",
              "              'équilibre': 532,\n",
              "              'donne': 533,\n",
              "              'entouré': 534,\n",
              "              'aide': 535,\n",
              "              'barbu': 536,\n",
              "              'blonds': 537,\n",
              "              'buvant': 538,\n",
              "              'chantant': 539,\n",
              "              'cigarette': 540,\n",
              "              'coup': 541,\n",
              "              'couleurs': 542,\n",
              "              'cours': 543,\n",
              "              'même': 544,\n",
              "              'paysage': 545,\n",
              "              'pluie': 546,\n",
              "              'skateur': 547,\n",
              "              'vieille': 548,\n",
              "              'apprête': 549,\n",
              "              'ballons': 550,\n",
              "              'bottes': 551,\n",
              "              'boy': 552,\n",
              "              'dame': 553,\n",
              "              'gants': 554,\n",
              "              'morceau': 555,\n",
              "              'pilote': 556,\n",
              "              'surf': 557,\n",
              "              'verts': 558,\n",
              "              'amis': 559,\n",
              "              'artiste': 560,\n",
              "              'battent': 561,\n",
              "              'colorés': 562,\n",
              "              'côte': 563,\n",
              "              'doigt': 564,\n",
              "              'drapeaux': 565,\n",
              "              'frappe': 566,\n",
              "              'grise': 567,\n",
              "              'habillés': 568,\n",
              "              'longue': 569,\n",
              "              'rocheuse': 570,\n",
              "              'véhicule': 571,\n",
              "              'âgées': 572,\n",
              "              'falaise': 573,\n",
              "              'jardin': 574,\n",
              "              'poteau': 575,\n",
              "              'produits': 576,\n",
              "              'traversent': 577,\n",
              "              'bien': 578,\n",
              "              'construction': 579,\n",
              "              'roulant': 580,\n",
              "              'bouteille': 581,\n",
              "              'bâtiments': 582,\n",
              "              'petites': 583,\n",
              "              'préparant': 584,\n",
              "              'rassemblent': 585,\n",
              "              'snowboardeur': 586,\n",
              "              'centre': 587,\n",
              "              'foncé': 588,\n",
              "              'mange': 589,\n",
              "              'martiaux': 590,\n",
              "              'peinture': 591,\n",
              "              'seau': 592,\n",
              "              'surfeur': 593,\n",
              "              'arts': 594,\n",
              "              'bowling': 595,\n",
              "              'caméra': 596,\n",
              "              'courses': 597,\n",
              "              'grands': 598,\n",
              "              'musiciens': 599,\n",
              "              'parler': 600,\n",
              "              'policier': 601,\n",
              "              'robes': 602,\n",
              "              'temps': 603,\n",
              "              'vendeur': 604,\n",
              "              'vitrine': 605,\n",
              "              'art': 606,\n",
              "              'but': 607,\n",
              "              'chevaux': 608,\n",
              "              'fils': 609,\n",
              "              'masque': 610,\n",
              "              'vertes': 611,\n",
              "              'boule': 612,\n",
              "              'capuche': 613,\n",
              "              'chantier': 614,\n",
              "              'couverture': 615,\n",
              "              'lire': 616,\n",
              "              'mangent': 617,\n",
              "              'nage': 618,\n",
              "              'ayant': 619,\n",
              "              'longues': 620,\n",
              "              'pas': 621,\n",
              "              'pavée': 622,\n",
              "              'penche': 623,\n",
              "              'peu': 624,\n",
              "              'préparent': 625,\n",
              "              'traversant': 626,\n",
              "              'collier': 627,\n",
              "              'espace': 628,\n",
              "              'filet': 629,\n",
              "              'lieu': 630,\n",
              "              'ouverte': 631,\n",
              "              'roses': 632,\n",
              "              'skieur': 633,\n",
              "              'échelle': 634,\n",
              "              'étendue': 635,\n",
              "              'avoir': 636,\n",
              "              'bulles': 637,\n",
              "              'canne': 638,\n",
              "              'immeuble': 639,\n",
              "              'manches': 640,\n",
              "              'matériel': 641,\n",
              "              'motocross': 642,\n",
              "              'orchestre': 643,\n",
              "              'premier': 644,\n",
              "              'âgés': 645,\n",
              "              'avion': 646,\n",
              "              'bikini': 647,\n",
              "              'descendant': 648,\n",
              "              'différentes': 649,\n",
              "              'photographe': 650,\n",
              "              'pompiers': 651,\n",
              "              'poussette': 652,\n",
              "              'rayée': 653,\n",
              "              'rivage': 654,\n",
              "              'vend': 655,\n",
              "              'écran': 656,\n",
              "              'adolescent': 657,\n",
              "              'allongée': 658,\n",
              "              'batterie': 659,\n",
              "              'discutent': 660,\n",
              "              'droite': 661,\n",
              "              'gâteau': 662,\n",
              "              'parking': 663,\n",
              "              'poisson': 664,\n",
              "              'remplie': 665,\n",
              "              'tirant': 666,\n",
              "              'vagues': 667,\n",
              "              'mer': 668,\n",
              "              'sombre': 669,\n",
              "              'tour': 670,\n",
              "              'vendant': 671,\n",
              "              'équipes': 672,\n",
              "              'boissons': 673,\n",
              "              'conversation': 674,\n",
              "              'essaie': 675,\n",
              "              'marcher': 676,\n",
              "              'violette': 677,\n",
              "              'coucher': 678,\n",
              "              'couvert': 679,\n",
              "              'laisse': 680,\n",
              "              'on': 681,\n",
              "              'recouverte': 682,\n",
              "              'skate': 683,\n",
              "              'taureau': 684,\n",
              "              'terrasse': 685,\n",
              "              'traverser': 686,\n",
              "              'violon': 687,\n",
              "              'été': 688,\n",
              "              'animée': 689,\n",
              "              'boue': 690,\n",
              "              'cascade': 691,\n",
              "              'clients': 692,\n",
              "              'comptoir': 693,\n",
              "              'coupe': 694,\n",
              "              'station': 695,\n",
              "              'tableau': 696,\n",
              "              'affiche': 697,\n",
              "              'allée': 698,\n",
              "              'argent': 699,\n",
              "              'boisson': 700,\n",
              "              'mariage': 701,\n",
              "              'oiseau': 702,\n",
              "              'pause': 703,\n",
              "              'policiers': 704,\n",
              "              'attrape': 705,\n",
              "              'chauve': 706,\n",
              "              'ciment': 707,\n",
              "              'coloré': 708,\n",
              "              'cordes': 709,\n",
              "              'cravate': 710,\n",
              "              'dents': 711,\n",
              "              'mariée': 712,\n",
              "              'montrant': 713,\n",
              "              'peluche': 714,\n",
              "              'roule': 715,\n",
              "              'vient': 716,\n",
              "              'vole': 717,\n",
              "              'écharpe': 718,\n",
              "              'étudiants': 719,\n",
              "              'joueuse': 720,\n",
              "              'objets': 721,\n",
              "              'pelle': 722,\n",
              "              'promenant': 723,\n",
              "              'randonnée': 724,\n",
              "              'rassemblées': 725,\n",
              "              'roller': 726,\n",
              "              'tasse': 727,\n",
              "              'voie': 728,\n",
              "              'volley': 729,\n",
              "              'coureur': 730,\n",
              "              'coureurs': 731,\n",
              "              'cuir': 732,\n",
              "              'foulard': 733,\n",
              "              'monsieur': 734,\n",
              "              'recouvert': 735,\n",
              "              'rit': 736,\n",
              "              'rousse': 737,\n",
              "              'sort': 738,\n",
              "              'surfe': 739,\n",
              "              'électrique': 740,\n",
              "              'adolescents': 741,\n",
              "              'animal': 742,\n",
              "              'barbecue': 743,\n",
              "              \"c'\": 744,\n",
              "              'conduit': 745,\n",
              "              'jouets': 746,\n",
              "              'miroir': 747,\n",
              "              'métal': 748,\n",
              "              'trou': 749,\n",
              "              ' ': 750,\n",
              "              'chemisier': 751,\n",
              "              'clown': 752,\n",
              "              'hors': 753,\n",
              "              'juste': 754,\n",
              "              'lève': 755,\n",
              "              'marathon': 756,\n",
              "              'membres': 757,\n",
              "              'motard': 758,\n",
              "              'ombre': 759,\n",
              "              'paroi': 760,\n",
              "              'vestes': 761,\n",
              "              'arbitre': 762,\n",
              "              'discutant': 763,\n",
              "              'golf': 764,\n",
              "              'jette': 765,\n",
              "              'ne': 766,\n",
              "              'passage': 767,\n",
              "              'pierres': 768,\n",
              "              'promenade': 769,\n",
              "              'salon': 770,\n",
              "              'stade': 771,\n",
              "              'suspendu': 772,\n",
              "              'tables': 773,\n",
              "              'écouteurs': 774,\n",
              "              'chef': 775,\n",
              "              'fond': 776,\n",
              "              \"jusqu'\": 777,\n",
              "              'manège': 778,\n",
              "              'prairie': 779,\n",
              "              'sandales': 780,\n",
              "              'taille': 781,\n",
              "              'balance': 782,\n",
              "              'boit': 783,\n",
              "              'courts': 784,\n",
              "              'endroit': 785,\n",
              "              'habillées': 786,\n",
              "              'microscope': 787,\n",
              "              'poussant': 788,\n",
              "              'profonde': 789,\n",
              "              'ruelle': 790,\n",
              "              'viande': 791,\n",
              "              'vive': 792,\n",
              "              'volant': 793,\n",
              "              'église': 794,\n",
              "              'épaules': 795,\n",
              "              'accordéon': 796,\n",
              "              'désert': 797,\n",
              "              'effectuant': 798,\n",
              "              'fume': 799,\n",
              "              'peut': 800,\n",
              "              'plantes': 801,\n",
              "              'protection': 802,\n",
              "              'quartier': 803,\n",
              "              'seul': 804,\n",
              "              'snowboard': 805,\n",
              "              'souriante': 806,\n",
              "              'tunnel': 807,\n",
              "              'barrière': 808,\n",
              "              'batte': 809,\n",
              "              'chat': 810,\n",
              "              'kaki': 811,\n",
              "              'kayak': 812,\n",
              "              'mouvement': 813,\n",
              "              'pays': 814,\n",
              "              'raquette': 815,\n",
              "              'représentant': 816,\n",
              "              'rues': 817,\n",
              "              'surplombant': 818,\n",
              "              'toutes': 819,\n",
              "              'accroupi': 820,\n",
              "              'bâtons': 821,\n",
              "              'chinois': 822,\n",
              "              'courir': 823,\n",
              "              'donnant': 824,\n",
              "              'laboratoire': 825,\n",
              "              'multicolore': 826,\n",
              "              'park': 827,\n",
              "              'réunis': 828,\n",
              "              'sauvetage': 829,\n",
              "              'sculpture': 830,\n",
              "              'signe': 831,\n",
              "              'tronc': 832,\n",
              "              'tuyau': 833,\n",
              "              'virage': 834,\n",
              "              'bordée': 835,\n",
              "              'boîte': 836,\n",
              "              'caisse': 837,\n",
              "              'cet': 838,\n",
              "              'colorée': 839,\n",
              "              'cérémonie': 840,\n",
              "              'karaté': 841,\n",
              "              'nageant': 842,\n",
              "              'police': 843,\n",
              "              'profitant': 844,\n",
              "              'rangée': 845,\n",
              "              'repose': 846,\n",
              "              'scooter': 847,\n",
              "              'sieste': 848,\n",
              "              'trampoline': 849,\n",
              "              'travailler': 850,\n",
              "              'télescope': 851,\n",
              "              'va': 852,\n",
              "              'énorme': 853,\n",
              "              'balustrade': 854,\n",
              "              'batteur': 855,\n",
              "              'effectue': 856,\n",
              "              'escaliers': 857,\n",
              "              'fumant': 858,\n",
              "              'grimpe': 859,\n",
              "              'jambe': 860,\n",
              "              'participant': 861,\n",
              "              'piétons': 862,\n",
              "              'produit': 863,\n",
              "              'promènent': 864,\n",
              "              'remorque': 865,\n",
              "              'ruisseau': 866,\n",
              "              'semblent': 867,\n",
              "              'vendre': 868,\n",
              "              'vide': 869,\n",
              "              'volleyball': 870,\n",
              "              'épaule': 871,\n",
              "              'campagne': 872,\n",
              "              'endormi': 873,\n",
              "              'entourée': 874,\n",
              "              'entrée': 875,\n",
              "              'girls': 876,\n",
              "              'gymnase': 877,\n",
              "              'hauts': 878,\n",
              "              'motifs': 879,\n",
              "              'nettoie': 880,\n",
              "              'nettoyant': 881,\n",
              "              'nez': 882,\n",
              "              'rient': 883,\n",
              "              'roulettes': 884,\n",
              "              'soirée': 885,\n",
              "              'soit': 886,\n",
              "              'solitaire': 887,\n",
              "              'tissu': 888,\n",
              "              'touche': 889,\n",
              "              'tout-petit': 890,\n",
              "              'têtes': 891,\n",
              "              'aire': 892,\n",
              "              'barre': 893,\n",
              "              'bol': 894,\n",
              "              'bondée': 895,\n",
              "              'brosse': 896,\n",
              "              'cadre': 897,\n",
              "              'cercle': 898,\n",
              "              'chemises': 899,\n",
              "              'colorées': 900,\n",
              "              'descendent': 901,\n",
              "              'dessous': 902,\n",
              "              'doigts': 903,\n",
              "              'eaux': 904,\n",
              "              'enneigé': 905,\n",
              "              'escaladant': 906,\n",
              "              'examine': 907,\n",
              "              'gardien': 908,\n",
              "              'lumière': 909,\n",
              "              'lumières': 910,\n",
              "              'paille': 911,\n",
              "              'poubelle': 912,\n",
              "              'projet': 913,\n",
              "              'riant': 914,\n",
              "              'roue': 915,\n",
              "              'roux': 916,\n",
              "              'sept': 917,\n",
              "              'uns': 918,\n",
              "              'voici': 919,\n",
              "              'voit': 920,\n",
              "              'écoute': 921,\n",
              "              'balaie': 922,\n",
              "              'certains': 923,\n",
              "              'ces': 924,\n",
              "              'couper': 925,\n",
              "              'façade': 926,\n",
              "              'gare': 927,\n",
              "              'glissant': 928,\n",
              "              'gonflable': 929,\n",
              "              'gymnaste': 930,\n",
              "              'mettant': 931,\n",
              "              'militaire': 932,\n",
              "              'moment': 933,\n",
              "              'pantalons': 934,\n",
              "              'participent': 935,\n",
              "              'penché': 936,\n",
              "              'roulent': 937,\n",
              "              'sale': 938,\n",
              "              'soldats': 939,\n",
              "              'utilisent': 940,\n",
              "              'vin': 941,\n",
              "              'école': 942,\n",
              "              'équipement': 943,\n",
              "              'adverse': 944,\n",
              "              'afro-américain': 945,\n",
              "              'balcon': 946,\n",
              "              'bondé': 947,\n",
              "              'canoë': 948,\n",
              "              'combat': 949,\n",
              "              'coupant': 950,\n",
              "              'divers': 951,\n",
              "              'façon': 952,\n",
              "              'figures': 953,\n",
              "              'fresque': 954,\n",
              "              'gril': 955,\n",
              "              'guitariste': 956,\n",
              "              'haute': 957,\n",
              "              'hautes': 958,\n",
              "              'jambes': 959,\n",
              "              'jetée': 960,\n",
              "              'lanceur': 961,\n",
              "              'lançant': 962,\n",
              "              'manteaux': 963,\n",
              "              'marteau': 964,\n",
              "              'montent': 965,\n",
              "              'obstacle': 966,\n",
              "              'peignant': 967,\n",
              "              'pompier': 968,\n",
              "              'randonneur': 969,\n",
              "              'randonneurs': 970,\n",
              "              'shorts': 971,\n",
              "              'type': 972,\n",
              "              'écoutant': 973,\n",
              "              'éloigne': 974,\n",
              "              'animaux': 975,\n",
              "              'appuie': 976,\n",
              "              'articles': 977,\n",
              "              'bagages': 978,\n",
              "              'cou': 979,\n",
              "              'couché': 980,\n",
              "              'linge': 981,\n",
              "              'livres': 982,\n",
              "              'monde': 983,\n",
              "              'new': 984,\n",
              "              'nouveau': 985,\n",
              "              'oiseaux': 986,\n",
              "              'parcours': 987,\n",
              "              'partie': 988,\n",
              "              'plat': 989,\n",
              "              'queue': 990,\n",
              "              'rassemblés': 991,\n",
              "              'ruban': 992,\n",
              "              'réparer': 993,\n",
              "              'sourire': 994,\n",
              "              'supermarché': 995,\n",
              "              'surface': 996,\n",
              "              'traditionnels': 997,\n",
              "              'travaux': 998,\n",
              "              'vache': 999,\n",
              "              ...}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NFaNbhle6eW"
      },
      "source": [
        "### Create iterators for train, valid and test.\r\n",
        "\r\n",
        "BucketIterator is used instead of Standard Iterator. BucketIterator defines an iterator that batches examples of similar lengths together.\r\n",
        "\r\n",
        "Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch.\r\n",
        "\r\n",
        "batch.src - [ (128) , (128), .. 23 times]**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJybIVRQdH8X"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twttp5LaqIxb",
        "outputId": "ec5e2df0-e51d-460b-df97-723844e817af"
      },
      "source": [
        "device"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDSe1FX5e_J_"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \r\n",
        "                                                                      batch_size = BATCH_SIZE, device = device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp-qzheqi6QI"
      },
      "source": [
        "batch = next(iter(train_iterator))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEQPQkI9jF6f",
        "outputId": "805d7ac3-7cdd-4364-d97d-7a20f4f58a9d"
      },
      "source": [
        "# Batch contains src and trg. Can be accessed as batch.src and batch.trg\r\n",
        "# batch.src groups the first element of all sequences in batch of 128, then groups second element of sequence in batch 128.\r\n",
        "print(type(batch))\r\n",
        "print(batch)\r\n",
        "print(\"Length of a source sequence\", len(batch.src))\r\n",
        "print(\"Length of source at first index\", len(batch.src[0]))\r\n",
        "print(\"Values at source first index\", batch.src[0])\r\n",
        "print(batch.trg[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.data.batch.Batch'>\n",
            "\n",
            "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 23x128 (GPU 0)]\n",
            "Length of a source sequence 26\n",
            "Length of source at first index 128\n",
            "Values at source first index tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([   8,   54,    5,    5,    5,    5,    8,    5,   13,    5,    5,    5,\n",
            "           5,    5,    5, 2892,    5,    5,    5,   18,    5,    5,   18,    8,\n",
            "        2213,    5,    5,    5,    5,    8,    8,   18,   18,    5,    5,   96,\n",
            "           8,    8,    5,    8,    8,    5,  105,    5,   18,    8,    5,    8,\n",
            "           8,    5,    5,    5,    8, 2761,    8,    5,    5,   13,    5,   18,\n",
            "          76,   43,   12,   18,   76,   18,   43,    5,    8,   39,    5,    8,\n",
            "          43,    5,    5,   18,    5,   45,   65,    5,   18,    5,    8,   18,\n",
            "           5,    5,    5,   18,  330,    8,    5,    5,    5,    8,   39,    5,\n",
            "           5,    5, 4729,    5,   18,   18,    5,    5,    5,   36,    8,    8,\n",
            "          18,   18,    8,   18,    8,    5,    5,    8,    8,    5,    5,    8,\n",
            "           8,   15,    5,    5,   15,    8,    5,    5], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0GUwBcw8IPl"
      },
      "source": [
        "### Build seq2seq model\r\n",
        "\r\n",
        "building our model in three parts. The encoder, the decoder and a seq2seq model that encapsulates the encoder and decoder and will provide a way to interface with each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjk1qDQViW-o"
      },
      "source": [
        "\r\n",
        "\r\n",
        "#### Encoder\r\n",
        "\r\n",
        "Input - X = {x1, x2, x3, .. xT}\r\n",
        "\r\n",
        "Embedded input - E(X) = {e(x1), e(x2), ... e(xT)}\r\n",
        "\r\n",
        "Hidden state - H = {h1, h2, h3,.... ,hT}\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "(h_t^1, c_t^1) &= \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))\\\\\r\n",
        "(h_t^2, c_t^2) &= \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "Note how only our hidden state from the first layer is passed as input to the second layer, and not the cell state.\r\n",
        "\r\n",
        "So our encoder looks something like this: \r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq2.png?raw=1)\r\n",
        "\r\n",
        "We create this in code by making an `Encoder` module, which requires we inherit from `torch.nn.Module` and use the `super().__init__()` as some boilerplate code. The encoder takes the following arguments:\r\n",
        "- `input_dim` is the size/dimensionality of the one-hot vectors that will be input to the encoder. This is equal to the input (source) vocabulary size.\r\n",
        "- `emb_dim` is the dimensionality of the embedding layer. This layer converts the one-hot vectors into dense vectors with `emb_dim` dimensions. \r\n",
        "- `hid_dim` is the dimensionality of the hidden and cell states.\r\n",
        "- `n_layers` is the number of layers in the RNN.\r\n",
        "- `dropout` is the amount of dropout to use. This is a regularization parameter to prevent overfitting. Check out [this](https://www.coursera.org/lecture/deep-neural-network/understanding-dropout-YaGbR) for more details about dropout.\r\n",
        "\r\n",
        "We aren't going to discuss the embedding layer in detail during these tutorials. All we need to know is that there is a step before the words - technically, the indexes of the words - are passed into the RNN, where the words are transformed into vectors. To read more about word embeddings, check these articles: [1](https://monkeylearn.com/blog/word-embeddings-transform-text-numbers/), [2](http://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html), [3](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/), [4](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/). \r\n",
        "\r\n",
        "The embedding layer is created using `nn.Embedding`, the LSTM with `nn.LSTM` and a dropout layer with `nn.Dropout`. Check the PyTorch [documentation](https://pytorch.org/docs/stable/nn.html) for more about these.\r\n",
        "\r\n",
        "One thing to note is that the `dropout` argument to the LSTM is how much dropout to apply between the layers of a multi-layer RNN, i.e. between the hidden states output from layer $l$ and those same hidden states being used for the input of layer $l+1$.\r\n",
        "\r\n",
        "In the `forward` method, we pass in the source sentence, $X$, which is converted into dense vectors using the `embedding` layer, and then dropout is applied. These embeddings are then passed into the RNN. As we pass a whole sequence to the RNN, it will automatically do the recurrent calculation of the hidden states over the whole sequence for us! Notice that we do not pass an initial hidden or cell state to the RNN. This is because, as noted in the [documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM), that if no hidden/cell state is passed to the RNN, it will automatically create an initial hidden/cell state as a tensor of all zeros. \r\n",
        "\r\n",
        "The RNN returns: `outputs` (the top-layer hidden state for each time-step), `hidden` (the final hidden state for each layer, $h_T$, stacked on top of each other) and `cell` (the final cell state for each layer, $c_T$, stacked on top of each other).\r\n",
        "\r\n",
        "As we only need the final hidden and cell states (to make our context vector), `forward` only returns `hidden` and `cell`. \r\n",
        "\r\n",
        "The sizes of each of the tensors is left as comments in the code. In this implementation `n_directions` will always be 1, however note that bidirectional RNNs (covered in tutorial 3) will have `n_directions` as 2.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vbcXGCmiZTI"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "\r\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "    def forward(self, src):\r\n",
        "        #src = [src len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(src))\r\n",
        "        \r\n",
        "        #embedded = [src len, batch size, emb dim]\r\n",
        "        \r\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\r\n",
        "        \r\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #outputs are always from the top hidden layer\r\n",
        "        \r\n",
        "        return hidden, cell"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JYEkbJ8yvez"
      },
      "source": [
        "#### Decoder\r\n",
        "\r\n",
        "The Decoder class does a single step of decoding, i.e. it ouputs single token per time-step. \r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq3.png?raw=1)\r\n",
        "\r\n",
        "The `Decoder` class does a single step of decoding, i.e. it ouputs single token per time-step. The first layer will receive a hidden and cell state from the previous time-step, $(s_{t-1}^1, c_{t-1}^1)$, and feeds it through the LSTM with the current embedded token, $y_t$, to produce a new hidden and cell state, $(s_t^1, c_t^1)$. The subsequent layers will use the hidden state from the layer below, $s_t^{l-1}$, and the previous hidden and cell states from their layer, $(s_{t-1}^l, c_{t-1}^l)$. This provides equations very similar to those in the encoder.\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(d(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\r\n",
        "(s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "Remember that the initial hidden and cell states to our decoder are our context vectors, which are the final hidden and cell states of our encoder from the same layer, i.e. $(s_0^l,c_0^l)=z^l=(h_T^l,c_T^l)$.\r\n",
        "\r\n",
        "We then pass the hidden state from the top layer of the RNN, $s_t^L$, through a linear layer, $f$, to make a prediction of what the next token in the target (output) sequence should be, $\\hat{y}_{t+1}$. \r\n",
        "\r\n",
        "$$\\hat{y}_{t+1} = f(s_t^L)$$\r\n",
        "\r\n",
        "The arguments and initialization are similar to the `Encoder` class, except we now have an `output_dim` which is the size of the vocabulary for the output/target. There is also the addition of the `Linear` layer, used to make the predictions from the top layer hidden state.\r\n",
        "\r\n",
        "Within the `forward` method, we accept a batch of input tokens, previous hidden states and previous cell states. As we are only decoding one token at a time, the input tokens will always have a sequence length of 1. We `unsqueeze` the input tokens to add a sentence length dimension of 1. Then, similar to the encoder, we pass through an embedding layer and apply dropout. This batch of embedded tokens is then passed into the RNN with the previous hidden and cell states. This produces an `output` (hidden state from the top layer of the RNN), a new `hidden` state (one for each layer, stacked on top of each other) and a new `cell` state (also one per layer, stacked on top of each other). We then pass the `output` (after getting rid of the sentence length dimension) through the linear layer to receive our `prediction`. We then return the `prediction`, the new `hidden` state and the new `cell` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vascu3gbyx4U"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "\r\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "    def forward(self, input, hidden, cell):\r\n",
        "        #input = [batch size]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        input = input.unsqueeze(0)\r\n",
        "        #input = [1, batch size]\r\n",
        "\r\n",
        "        embedded = self.dropout(self.embedding(input))\r\n",
        "        #embedded = [1, batch size, emb dim]\r\n",
        "\r\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\r\n",
        "\r\n",
        "        #output = [seq len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\r\n",
        "        #output = [1, batch size, hid dim]\r\n",
        "        #hidden = [n layers, batch size, hid dim]\r\n",
        "        #cell = [n layers, batch size, hid dim]\r\n",
        "\r\n",
        "        prediction = self.fc_out(output.squeeze(0))\r\n",
        "        #prediction = [batch size, output dim]\r\n",
        "        \r\n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyU7PX4F7-j3"
      },
      "source": [
        "#### Seq2Seq model\r\n",
        "\r\n",
        "For the final part of the implemenetation, we'll implement the seq2seq model. This will handle: \r\n",
        "- receiving the input/source sentence\r\n",
        "- using the encoder to produce the context vectors \r\n",
        "- using the decoder to produce the predicted output/target sentence\r\n",
        "\r\n",
        "Our full model will look like this:\r\n",
        "\r\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq4.png?raw=1)\r\n",
        "\r\n",
        "The `Seq2Seq` model takes in an `Encoder`, `Decoder`, and a `device` (used to place tensors on the GPU, if it exists).\r\n",
        "\r\n",
        "For this implementation, we have to ensure that the number of layers and the hidden (and cell) dimensions are equal in the `Encoder` and `Decoder`. This is not always the case, we do not necessarily need the same number of layers or the same hidden dimension sizes in a sequence-to-sequence model. However, if we did something like having a different number of layers then we would need to make decisions about how this is handled. For example, if our encoder has 2 layers and our decoder only has 1, how is this handled? Do we average the two context vectors output by the decoder? Do we pass both through a linear layer? Do we only use the context vector from the highest layer? Etc.\r\n",
        "\r\n",
        "Our `forward` method takes the source sentence, target sentence and a teacher-forcing ratio. The teacher forcing ratio is used when training our model. When decoding, at each time-step we will predict what the next token in the target sequence will be from the previous tokens decoded, $\\hat{y}_{t+1}=f(s_t^L)$. With probability equal to the teaching forcing ratio (`teacher_forcing_ratio`) we will use the actual ground-truth next token in the sequence as the input to the decoder during the next time-step. However, with probability `1 - teacher_forcing_ratio`, we will use the token that the model predicted as the next input to the model, even if it doesn't match the actual next token in the sequence.  \r\n",
        "\r\n",
        "The first thing we do in the `forward` method is to create an `outputs` tensor that will store all of our predictions, $\\hat{Y}$.\r\n",
        "\r\n",
        "We then feed the input/source sentence, `src`, into the encoder and receive out final hidden and cell states.\r\n",
        "\r\n",
        "The first input to the decoder is the start of sequence (`<sos>`) token. As our `trg` tensor already has the `<sos>` token appended (all the way back when we defined the `init_token` in our `TRG` field) we get our $y_1$ by slicing into it. We know how long our target sentences should be (`max_len`), so we loop that many times. The last token input into the decoder is the one **before** the `<eos>` token - the `<eos>` token is never input into the decoder. \r\n",
        "\r\n",
        "During each iteration of the loop, we:\r\n",
        "- pass the input, previous hidden and previous cell states ($y_t, s_{t-1}, c_{t-1}$) into the decoder\r\n",
        "- receive a prediction, next hidden state and next cell state ($\\hat{y}_{t+1}, s_{t}, c_{t}$) from the decoder\r\n",
        "- place our prediction, $\\hat{y}_{t+1}$/`output` in our tensor of predictions, $\\hat{Y}$/`outputs`\r\n",
        "- decide if we are going to \"teacher force\" or not\r\n",
        "    - if we do, the next `input` is the ground-truth next token in the sequence, $y_{t+1}$/`trg[t]`\r\n",
        "    - if we don't, the next `input` is the predicted next token in the sequence, $\\hat{y}_{t+1}$/`top1`, which we get by doing an `argmax` over the output tensor\r\n",
        "    \r\n",
        "Once we've made all of our predictions, we return our tensor full of predictions, $\\hat{Y}$/`outputs`.\r\n",
        "\r\n",
        "**Note**: our decoder loop starts at 1, not 0. This means the 0th element of our `outputs` tensor remains all zeros. So our `trg` and `outputs` look something like:\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "\\text{trg} = [<sos>, &y_1, y_2, y_3, <eos>]\\\\\r\n",
        "\\text{outputs} = [0, &\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "Later on when we calculate the loss, we cut off the first element of each tensor to get:\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "\\text{trg} = [&y_1, y_2, y_3, <eos>]\\\\\r\n",
        "\\text{outputs} = [&\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\r\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_jhpVr9-MOE"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder, device):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.device = device\r\n",
        "\r\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\r\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\r\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\r\n",
        "            \"Encoder and decoder must have equal number of layers!\"\r\n",
        "    \r\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "        #src = [src len, batch size]\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\r\n",
        "\r\n",
        "        # Dimensions to create output tensor to store results from decoder.\r\n",
        "        batch_size = trg.shape[1]\r\n",
        "        trg_len = trg.shape[0]\r\n",
        "        trg_vocab_size = self.decoder.output_dim\r\n",
        "\r\n",
        "        #tensor to store decoder outputs\r\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "\r\n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\r\n",
        "        hidden, cell = self.encoder(src)\r\n",
        "\r\n",
        "        #first input to the decoder is the <sos> tokens\r\n",
        "        input = trg[0,:]\r\n",
        "\r\n",
        "        for t in range(1, trg_len):\r\n",
        "            #insert input token embedding, previous hidden and previous cell states\r\n",
        "            #receive output tensor (predictions) and new hidden and cell states\r\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\r\n",
        "\r\n",
        "            #place predictions in a tensor holding predictions for each token\r\n",
        "            outputs[t] = output\r\n",
        "\r\n",
        "            #decide if we are going to use teacher forcing or not\r\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "\r\n",
        "            #get the highest predicted token from our predictions\r\n",
        "            top1 = output.argmax(1)\r\n",
        "\r\n",
        "            #if teacher forcing, use actual next token as next input\r\n",
        "            #if not, use predicted token\r\n",
        "            input = trg[t] if teacher_force else top1\r\n",
        "        \r\n",
        "        return outputs\r\n",
        "\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsqxkAaQBrwr"
      },
      "source": [
        "### Training the Seq2Seq model\r\n",
        "\r\n",
        "First, we'll initialize our model. As mentioned before, the input and output dimensions are defined by the size of the vocabulary. The embedding dimesions and dropout for the encoder and decoder can be different, but the number of layers and the size of the hidden/cell states must be the same.\r\n",
        "\r\n",
        "We then define the encoder, decoder and then our Seq2Seq model, which we place on the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLTNICF9Bwz6"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "ENC_EMB_DIM = 256\r\n",
        "DEC_EMB_DIM = 256\r\n",
        "HID_DIM = 512\r\n",
        "N_LAYERS = 3\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3sZzvamC41Q"
      },
      "source": [
        "initialize all weights from a uniform distribution between -0.08 and +0.08, i.e.  U(−0.08,0.08) .\r\n",
        "\r\n",
        "We initialize weights in PyTorch by creating a function which we apply to our model. When using apply, the init_weights function will be called on every module and sub-module within our model. For each module we loop through all of the parameters and sample them from a uniform distribution with nn.init.uniform_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2FT2v33CkN8",
        "outputId": "ecb64ce4-f30f-4642-85ca-2ea0cd80efbb"
      },
      "source": [
        "def init_weights(m):\r\n",
        "    for name, param in m.named_parameters():\r\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\r\n",
        "\r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(6462, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=3, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=3, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I3ZNXYxEYbO",
        "outputId": "5fd734be-cbf3-4bff-8a55-3982462d9168"
      },
      "source": [
        "w = torch.zeros(3, 5)\r\n",
        "print(w)\r\n",
        "nn.init.uniform_(w)\r\n",
        "print(w)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[0.0048, 0.0146, 0.0903, 0.0967, 0.1055],\n",
            "        [0.0428, 0.0134, 0.0433, 0.3332, 0.5763],\n",
            "        [0.7549, 0.5470, 0.9829, 0.0193, 0.7724]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw8Wt7G_Ef8d",
        "outputId": "2349d61b-564c-487e-ab22-fffcf432ec58"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 19,253,679 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe4oAyIDGJkm"
      },
      "source": [
        "### Define optimizer and criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr4xZX1GGOo1"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV-grcPEGlKW"
      },
      "source": [
        "we define our loss function. The CrossEntropyLoss function calculates both the log softmax as well as the negative log-likelihood of our predictions.\r\n",
        "\r\n",
        "Our loss function calculates the average loss per token, however by passing the index of the <pad> token as the ignore_index argument we ignore the loss whenever the target token is a padding token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGC_0OZTGZ-z"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6ffERJXIs_f"
      },
      "source": [
        "### Training loop\r\n",
        "\r\n",
        "Decoder loop starts at 1, not 0. This means the 0th element of our `outputs` tensor remains all zeros. So our `trg` and `outputs` look something like:\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "\\text{trg} = [<sos>, &y_1, y_2, y_3, <eos>]\\\\\r\n",
        "\\text{outputs} = [0, &\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "Here, when we calculate the loss, we cut off the first element of each tensor to get:\r\n",
        "\r\n",
        "$$\\begin{align*}\r\n",
        "\\text{trg} = [&y_1, y_2, y_3, <eos>]\\\\\r\n",
        "\\text{outputs} = [&\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, <eos>]\r\n",
        "\\end{align*}$$\r\n",
        "\r\n",
        "At each iteration:\r\n",
        "- get the source and target sentences from the batch, $X$ and $Y$\r\n",
        "- zero the gradients calculated from the last batch\r\n",
        "- feed the source and target into the model to get the output, $\\hat{Y}$\r\n",
        "- as the loss function only works on 2d inputs with 1d targets we need to flatten each of them with `.view`\r\n",
        "    - we slice off the first column of the output and target tensors as mentioned above\r\n",
        "- calculate the gradients with `loss.backward()`\r\n",
        "- clip the gradients to prevent them from exploding (a common issue in RNNs)\r\n",
        "- update the parameters of our model by doing an optimizer step\r\n",
        "- sum the loss value to a running total\r\n",
        "\r\n",
        "Finally, we return the loss that is averaged over all batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_5ySqLEIuhO"
      },
      "source": [
        "def train(model, iterator, optimizer, creiterion, clip):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    epoch_loss = 0\r\n",
        "\r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        src = batch.src\r\n",
        "        trg = batch.trg\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        output = model(src, trg)\r\n",
        "\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "        loss = criterion(output, trg)\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmZAgFijP3sc"
      },
      "source": [
        "### Testing loop\r\n",
        "\r\n",
        "Evaluation loop is similar to training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value.\r\n",
        "\r\n",
        "The iteration loop is similar (without the parameter updates), however we must ensure we turn teacher forcing off for evaluation. This will cause the model to only use it's own predictions to make further predictions within a sentence, which mirrors how it would be used in deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcyWxs8WQUls"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    epoch_loss = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "            src = batch.src\r\n",
        "            trg = batch.trg\r\n",
        "\r\n",
        "            output = model(src, trg, 0) # Turning off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "\r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-KUEhseRK3N"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs\r\n",
        "    "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBn4w1vWRSk_",
        "outputId": "a8ea6361-5723-4d07-c87e-a90eebadaf67"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 54s\n",
            "\tTrain Loss: 5.217 | Train PPL: 184.420\n",
            "\t Val. Loss: 5.145 |  Val. PPL: 171.640\n",
            "Epoch: 02 | Time: 0m 54s\n",
            "\tTrain Loss: 4.777 | Train PPL: 118.759\n",
            "\t Val. Loss: 5.182 |  Val. PPL: 178.044\n",
            "Epoch: 03 | Time: 0m 54s\n",
            "\tTrain Loss: 4.493 | Train PPL:  89.401\n",
            "\t Val. Loss: 5.007 |  Val. PPL: 149.486\n",
            "Epoch: 04 | Time: 0m 54s\n",
            "\tTrain Loss: 4.220 | Train PPL:  68.031\n",
            "\t Val. Loss: 4.889 |  Val. PPL: 132.835\n",
            "Epoch: 05 | Time: 0m 54s\n",
            "\tTrain Loss: 4.029 | Train PPL:  56.198\n",
            "\t Val. Loss: 4.689 |  Val. PPL: 108.706\n",
            "Epoch: 06 | Time: 0m 54s\n",
            "\tTrain Loss: 3.891 | Train PPL:  48.935\n",
            "\t Val. Loss: 4.609 |  Val. PPL: 100.429\n",
            "Epoch: 07 | Time: 0m 54s\n",
            "\tTrain Loss: 3.800 | Train PPL:  44.711\n",
            "\t Val. Loss: 4.430 |  Val. PPL:  83.919\n",
            "Epoch: 08 | Time: 0m 55s\n",
            "\tTrain Loss: 3.660 | Train PPL:  38.879\n",
            "\t Val. Loss: 4.365 |  Val. PPL:  78.688\n",
            "Epoch: 09 | Time: 0m 55s\n",
            "\tTrain Loss: 3.548 | Train PPL:  34.729\n",
            "\t Val. Loss: 4.238 |  Val. PPL:  69.248\n",
            "Epoch: 10 | Time: 0m 54s\n",
            "\tTrain Loss: 3.434 | Train PPL:  30.989\n",
            "\t Val. Loss: 4.174 |  Val. PPL:  64.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmmAxO04RtBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8604d332-26cb-4867-e637-83ad366ab3b9"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 4.093 | Test PPL:  59.902 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOsZq6560p1w"
      },
      "source": [
        "### Inferencing on sample sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJCgwl20t1b"
      },
      "source": [
        "sentence = \"L'homme traverse la route.\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq-JJfh84AJL",
        "outputId": "46716df1-3436-4316-ea53-8f661a74acaf"
      },
      "source": [
        "tokenized = tokenize_fr(sentence)\r\n",
        "tokenized"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.', 'route', 'la', 'traverse', 'homme', \"L'\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO3iF8Un4Sno",
        "outputId": "e5d3f74b-351f-4f05-c26e-21a5731de27c"
      },
      "source": [
        "indexed = [SRC.vocab.__dict__['stoi'][t] for t in tokenized]\r\n",
        "indexed"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 182, 16, 479, 12, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6va9hy547rh",
        "outputId": "6348ca5f-0986-4374-cf89-ffc55e565c8b"
      },
      "source": [
        "length = len(indexed)\r\n",
        "print(length)\r\n",
        " #src = [src len, batch size]\r\n",
        "input_tensor = torch.LongTensor(indexed)\r\n",
        "print(input_tensor.type())\r\n",
        "print(input_tensor.shape)\r\n",
        "input_tensor = input_tensor.unsqueeze(1).to(device).long()\r\n",
        "print(input_tensor.shape)\r\n",
        "print(input_tensor)\r\n",
        "#trg = [trg len, batch size]\r\n",
        "dummy_target = torch.zeros((length, 1)).to(device)\r\n",
        "# dummy_target = torch.zeros(length).to(device)\r\n",
        "print(dummy_target.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "torch.LongTensor\n",
            "torch.Size([6])\n",
            "torch.Size([6, 1])\n",
            "tensor([[  5],\n",
            "        [182],\n",
            "        [ 16],\n",
            "        [479],\n",
            "        [ 12],\n",
            "        [  0]], device='cuda:0')\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "CpsJ5Oqx5yWU",
        "outputId": "f3e7cf15-d003-4844-e613-18e01b79b7c2"
      },
      "source": [
        "model = model.eval()\r\n",
        "prediction = model(input_tensor, dummy_target, 0)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-a2095bcab825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-4559f04ea0eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m#insert input token embedding, previous hidden and previous cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#receive output tensor (predictions) and new hidden and cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#place predictions in a tensor holding predictions for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-aaf9eab7e43a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#input = [1, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#embedded = [1, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    }
  ]
}